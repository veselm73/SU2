{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UuegVH0SMXf"
   },
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/veselm73/SU2/blob/main/notebooks/SU2_StarDist_inference.ipynb)\n\n# StarDist Model Comparison: Detection & Tracking\n\n**Authors:** Matyáš Veselý, Ruslan Guliev\n\nThis notebook compares **3 cell detection methods** on TIRF-SIM microscopy images:\n\n1. **StarDist (No Bonus)** - 100 epochs, no augmentation, 64 rays, no bonus training data\n2. **StarDist (Original)** - 100 epochs, no augmentation, 64 rays, with bonus training data\n3. **SOTA Method** - State-of-the-art baseline from competition\n\nAll methods are evaluated using **LapTrack** for cell tracking.\n\n---\n\n## Model Overview\n\n**StarDist** is a deep learning method for object detection that predicts star-convex polygons for each object. Key features:\n\n- **Architecture**: ResNet18 encoder + StarDist decoder with 64 radial rays\n- **Training**: 5-fold cross-validation ensemble (predictions averaged)\n- **Output**: Probability map + 64 ray distances → NMS → centroid coordinates\n\n### Training Configuration\n\n| Parameter | Value |\n|-----------|-------|\n| Encoder | ResNet18 |\n| N_Rays | 64 |\n| Epochs | 100 |\n| Augmentation | None |\n| Input Size | 256×256 (ROI crop) |\n| Normalization | Percentile (1st, 99.8th) |\n\n### Model Differences\n\n| Model | NMS Threshold | Description |\n|-------|---------------|-------------|\n| StarDist (No Bonus) | 0.2 | Trained without bonus data |\n| StarDist (Original) | 0.35 | Trained with bonus data |\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VU-s9NSBSMXj"
   },
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fm8l1jR0SMXj"
   },
   "outputs": [],
   "source": "# Install dependencies\n!pip install uv -q\n!uv pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121 --system -q\n!uv pip install \"numpy<2\" cellseg-models-pytorch pytorch-lightning tifffile scipy laptrack tabulate --system -q"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6yH_q6hSMXk",
    "outputId": "e2a63081-033f-4d2f-96ee-97e0990f413f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Repository: /content/SU2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    if not Path('/content/SU2').exists():\n",
    "        !git clone https://github.com/veselm73/SU2.git /content/SU2\n",
    "    os.chdir('/content/SU2')\n",
    "    repo_root = Path('/content/SU2')\n",
    "else:\n",
    "    repo_root = Path('.').resolve()\n",
    "    if repo_root.name == 'notebooks':\n",
    "        repo_root = repo_root.parent\n",
    "\n",
    "print(f\"Repository: {repo_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F_vOL2FxSMXl",
    "outputId": "8cc300b6-f197-4d5b-aa31-5a956e21d69c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from skimage.measure import regionprops\n",
    "import urllib.request\n",
    "import json\n",
    "import tifffile\n",
    "import networkx as nx\n",
    "from scipy import spatial\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from laptrack import LapTrack\n",
    "\n",
    "from cellseg_models_pytorch.postproc.functional.stardist.stardist import post_proc_stardist\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eNQk64w-SMXl"
   },
   "source": "## 2. Model Weight Paths\n\nConfigure paths to the two StarDist model weight directories."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N_6K7PYhSMXl",
    "outputId": "63dd2b16-6470-4339-8e3e-82698bda71b3"
   },
   "outputs": [],
   "source": "# Model weight paths - adjust these for your environment\nif IN_COLAB:\n    # Colab: download from GitHub or mount Google Drive\n    WEIGHTS_NOBONUS_DIR = repo_root / \"weights\" / \"100e_noaug_64rays_nobonus\" / \"competition\"\n    WEIGHTS_ORIGINAL_DIR = repo_root / \"weights\" / \"100e_noaug_64rays\" / \"competition\"\nelse:\n    # Local: use ansamble_weights folder\n    WEIGHTS_NOBONUS_DIR = Path(r\"C:\\Users\\Mateusz\\SU2\\ansamble_weights\\100e_noaug_64rays_nobonus\\competition\")\n    WEIGHTS_ORIGINAL_DIR = Path(r\"C:\\Users\\Mateusz\\SU2\\ansamble_weights\\100e_noaug_64rays\\SU2_competition_100epoch_noaug\\competition\")\n\nprint(f\"StarDist (No Bonus) weights: {WEIGHTS_NOBONUS_DIR}\")\nprint(f\"StarDist (Original) weights: {WEIGHTS_ORIGINAL_DIR}\")\n\n# Verify weights exist\nfor name, path in [(\"No Bonus\", WEIGHTS_NOBONUS_DIR), (\"Original\", WEIGHTS_ORIGINAL_DIR)]:\n    models_dir = path / \"models\"\n    if models_dir.exists():\n        n_weights = len(list(models_dir.glob(\"*.pth\")))\n        print(f\"  {name}: Found {n_weights} fold weights\")\n    else:\n        print(f\"  {name}: WARNING - weights not found at {models_dir}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aEryVVNSMXm"
   },
   "source": [
    "## 3. Model Definition & Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138,
     "referenced_widgets": [
      "a6e5da9b8d1e4390b628cb7bd2e4e1f2",
      "d3f4807acdc741948d54079c93ead2e7",
      "2d3623916ca446298c4707e65154a8c6",
      "7bf6124f51b845ebb60040c311aab414",
      "08e29a9975cf440fb8ec83ce1606dcea",
      "6c9e552abde34ba89fb74e61633e7442",
      "b9f189b19a2e4e6588ead99c9c9b5f20",
      "1b9563ab05de4acd9340f034b3359034",
      "b3cc356e9b8b4157a0d72d7720f8d59c",
      "33ef163ddbbd4c459dc8cf281428fe66",
      "4dec0b51260d4a07a2b59a23a9b2cc65"
     ]
    },
    "id": "a_GnPj8lSMXm",
    "outputId": "a7582129-362a-41cf-9159-4b74221b6548"
   },
   "outputs": [],
   "source": "import pytorch_lightning as pl\nfrom cellseg_models_pytorch.models.stardist.stardist import StarDist\n\nclass StarDistModel(pl.LightningModule):\n    def __init__(self, n_rays=64, encoder_name=\"resnet18\"):\n        super().__init__()\n        self.n_rays = n_rays\n        wrapper = StarDist(\n            n_nuc_classes=1, n_rays=n_rays, enc_name=encoder_name,\n            model_kwargs={\"encoder_kws\": {\"in_chans\": 1}}\n        )\n        self.model = wrapper.model\n\n    def forward(self, x):\n        return self.model(x)\n\n\ndef load_ensemble(weights_dir, name=\"Model\"):\n    \"\"\"Load 5-fold ensemble from a weights directory.\"\"\"\n    with open(weights_dir / \"model_config.json\") as f:\n        config = json.load(f)\n    with open(weights_dir / \"inference_config.json\") as f:\n        inf_config = json.load(f)\n\n    models = []\n    for fold in range(1, 6):\n        model = StarDistModel(n_rays=config['n_rays'], encoder_name=config['encoder_name'])\n        model.load_state_dict(torch.load(weights_dir / \"models\" / f\"fold_{fold}.pth\", map_location='cpu'))\n        model.eval().to(DEVICE)\n        models.append(model)\n\n    print(f\"[{name}] Loaded {len(models)} models: {config['encoder_name']}, n_rays={config['n_rays']}\")\n    print(f\"[{name}] Thresholds: prob={inf_config['prob_thresh']}, nms={inf_config['nms_thresh']}\")\n\n    return models, inf_config\n\n\n# Load both ensembles\nprint(\"Loading StarDist (No Bonus) ensemble...\")\nmodels_nobonus, config_nobonus = load_ensemble(WEIGHTS_NOBONUS_DIR, \"No Bonus\")\n\nprint(\"\\nLoading StarDist (Original) ensemble...\")\nmodels_original, config_original = load_ensemble(WEIGHTS_ORIGINAL_DIR, \"Original\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pm6Qk_u1SMXm"
   },
   "source": [
    "## 4. Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GF9QO2KYSMXm",
    "outputId": "f9080dbe-a6d1-4b9b-b6cd-08de2753ce0e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference functions defined.\n"
     ]
    }
   ],
   "source": [
    "# ROI configuration\n",
    "ROI = {'x_min': 256, 'x_max': 512, 'y_min': 512, 'y_max': 768}\n",
    "\n",
    "def preprocess(frame):\n",
    "    \"\"\"Percentile normalization.\"\"\"\n",
    "    frame = frame.astype(np.float32)\n",
    "    p1, p99 = np.percentile(frame, (1, 99.8))\n",
    "    return np.clip((frame - p1) / (p99 - p1 + 1e-8), 0, 1)\n",
    "\n",
    "\n",
    "def detect_single_frame(models, frame, prob_thresh, nms_thresh):\n",
    "    \"\"\"Run ensemble detection on a single frame.\"\"\"\n",
    "    x = torch.from_numpy(frame).float().unsqueeze(0).unsqueeze(0).to(DEVICE)\n",
    "\n",
    "    all_stardist, all_prob = [], []\n",
    "    with torch.no_grad():\n",
    "        for model in models:\n",
    "            out = model(x)['nuc']\n",
    "            all_stardist.append(out.aux_map.cpu().numpy()[0])\n",
    "            all_prob.append(torch.sigmoid(out.binary_map).cpu().numpy()[0, 0])\n",
    "\n",
    "    try:\n",
    "        labels = post_proc_stardist(\n",
    "            np.mean(all_prob, axis=0), np.mean(all_stardist, axis=0),\n",
    "            score_thresh=prob_thresh, iou_thresh=nms_thresh\n",
    "        )\n",
    "        return [(p.centroid[1], p.centroid[0]) for p in regionprops(labels)]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "\n",
    "def run_detection(video, models, prob_thresh, nms_thresh, roi=None):\n",
    "    \"\"\"Run detection on entire video.\"\"\"\n",
    "    if roi:\n",
    "        video_roi = video[:, roi['y_min']:roi['y_max'], roi['x_min']:roi['x_max']]\n",
    "    else:\n",
    "        video_roi = video\n",
    "        roi = {'x_min': 0, 'y_min': 0}\n",
    "\n",
    "    all_detections = []\n",
    "    detections_per_frame = []\n",
    "\n",
    "    for frame_idx in tqdm(range(len(video_roi)), desc=\"Detecting\"):\n",
    "        frame = preprocess(video_roi[frame_idx])\n",
    "        dets = detect_single_frame(models, frame, prob_thresh, nms_thresh)\n",
    "\n",
    "        # Store for tracking (local coords)\n",
    "        detections_per_frame.append(dets)\n",
    "\n",
    "        # Store for output (global coords)\n",
    "        for x, y in dets:\n",
    "            all_detections.append({\n",
    "                'frame': frame_idx,\n",
    "                'x': x + roi['x_min'],\n",
    "                'y': y + roi['y_min']\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(all_detections), detections_per_frame\n",
    "\n",
    "print(\"Inference functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2dDDgHySMXn"
   },
   "source": [
    "## 5. Tracking with LapTrack\n",
    "\n",
    "**LapTrack** uses Linear Assignment Problem (LAP) optimization for frame-to-frame linking with gap closing.\n",
    "\n",
    "Best configuration from benchmark (HOTA=0.9406):\n",
    "- `track_cost_cutoff`: 25 (5px squared)\n",
    "- `gap_closing_cost_cutoff`: 49 (7px squared)  \n",
    "- `gap_closing_max_frame_count`: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yy6RHzpkSMXn",
    "outputId": "b8a072c7-495c-44fd-ca4b-520227419063"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LapTrack config: track=5px, gap=7px, max_frames=1\n"
     ]
    }
   ],
   "source": [
    "# Best LapTrack configuration (HOTA=0.9406 on GT benchmark)\n",
    "LAPTRACK_CONFIG = {\n",
    "    'track_cost_cutoff': 25,        # 5px squared\n",
    "    'gap_closing_cost_cutoff': 49,  # 7px squared\n",
    "    'gap_closing_max_frame_count': 1\n",
    "}\n",
    "\n",
    "def run_tracking(detections_per_frame, config=LAPTRACK_CONFIG):\n",
    "    \"\"\"Track detections using LapTrack.\"\"\"\n",
    "    if len(detections_per_frame) == 0:\n",
    "        return pd.DataFrame(columns=['frame', 'x', 'y', 'track_id'])\n",
    "\n",
    "    # Prepare coordinates\n",
    "    coords_per_frame = []\n",
    "    for dets in detections_per_frame:\n",
    "        if len(dets) > 0:\n",
    "            coords_per_frame.append(np.array([[x, y] for x, y in dets]))\n",
    "        else:\n",
    "            coords_per_frame.append(np.empty((0, 2)))\n",
    "\n",
    "    # Run tracking\n",
    "    tracker = LapTrack(\n",
    "        track_cost_cutoff=config['track_cost_cutoff'],\n",
    "        gap_closing_cost_cutoff=config['gap_closing_cost_cutoff'],\n",
    "        gap_closing_max_frame_count=config['gap_closing_max_frame_count']\n",
    "    )\n",
    "\n",
    "    graph = tracker.predict(coords_per_frame)\n",
    "\n",
    "    # Extract tracks\n",
    "    records = []\n",
    "    for track_id, component in enumerate(nx.weakly_connected_components(graph)):\n",
    "        for node in component:\n",
    "            frame_idx, det_idx = node\n",
    "            if frame_idx < len(coords_per_frame) and det_idx < len(coords_per_frame[frame_idx]):\n",
    "                x, y = coords_per_frame[frame_idx][det_idx]\n",
    "                records.append({'frame': int(frame_idx), 'x': float(x), 'y': float(y), 'track_id': int(track_id)})\n",
    "\n",
    "    if not records:\n",
    "        return pd.DataFrame(columns=['frame', 'x', 'y', 'track_id'])\n",
    "\n",
    "    return pd.DataFrame(records).sort_values(['track_id', 'frame']).reset_index(drop=True)\n",
    "\n",
    "print(f\"LapTrack config: track={np.sqrt(LAPTRACK_CONFIG['track_cost_cutoff']):.0f}px, gap={np.sqrt(LAPTRACK_CONFIG['gap_closing_cost_cutoff']):.0f}px, max_frames={LAPTRACK_CONFIG['gap_closing_max_frame_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4c131ecf",
    "outputId": "9b5a9eaa-ff7a-49cc-c9c9-67fc1b927121"
   },
   "source": [
    "import os\n",
    "import io\n",
    "from google.colab import auth\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.http import MediaIoBaseDownload\n",
    "\n",
    "# 1. Authenticate user to access Drive\n",
    "print(\"Authenticating... Please allow access in the popup.\")\n",
    "auth.authenticate_user()\n",
    "\n",
    "# 2. Setup Drive Service\n",
    "drive_service = build('drive', 'v3')\n",
    "folder_id = '1sinaukYGrv9k4Ao0PsOyuillk6vQ5SyF'\n",
    "destination_dir = '/content/SU2/data/test_and_sota'\n",
    "\n",
    "# 3. Create destination directory\n",
    "os.makedirs(destination_dir, exist_ok=True)\n",
    "\n",
    "# 4. List files in the Drive folder\n",
    "query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
    "files = results.get('files', [])\n",
    "\n",
    "print(f\"Found {len(files)} files in Drive folder.\")\n",
    "\n",
    "# 5. Download files\n",
    "for file in files:\n",
    "    file_id = file['id']\n",
    "    file_name = file['name']\n",
    "    save_path = os.path.join(destination_dir, file_name)\n",
    "\n",
    "    print(f\"Downloading {file_name}...\")\n",
    "    request = drive_service.files().get_media(fileId=file_id)\n",
    "\n",
    "    with io.FileIO(save_path, 'wb') as fh:\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "        done = False\n",
    "        while done is False:\n",
    "            status, done = downloader.next_chunk()\n",
    "\n",
    "print(\"\\nDownload complete. Files in target directory:\")\n",
    "for f in os.listdir(destination_dir):\n",
    "    print(f\" - {f}\")"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Authenticating... Please allow access in the popup.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
      "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3 files in Drive folder.\n",
      "Downloading val.tif...\n",
      "Downloading sota.csv...\n",
      "Downloading val.csv...\n",
      "\n",
      "Download complete. Files in target directory:\n",
      " - val.tif\n",
      " - val.csv\n",
      " - sota.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gP05ftfqSMXn"
   },
   "source": [
    "---\n",
    "\n",
    "## 6. Load Test Data\n",
    "\n",
    "Load the validation video and annotations from the local `data/test_and_sota` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7lN-vs-kSMXn",
    "outputId": "a1d92329-0ad3-4e2a-f0b1-8c3c747ee400"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded: /content/SU2/data/test_and_sota/val.tif\n",
      "Shape: (722, 1024, 1024) (frames, height, width)\n",
      "\n",
      "Ground truth: 35688 detections, 438 tracks\n",
      "SOTA predictions: 31606 detections, 406 tracks\n"
     ]
    }
   ],
   "source": [
    "# Load test data from local folder\n",
    "DATA_DIR = repo_root / \"data\" / \"test_and_sota\"\n",
    "\n",
    "# Load video\n",
    "VIDEO_PATH = DATA_DIR / \"val.tif\"\n",
    "video = tifffile.imread(VIDEO_PATH)\n",
    "print(f\"Loaded: {VIDEO_PATH}\")\n",
    "print(f\"Shape: {video.shape} (frames, height, width)\")\n",
    "\n",
    "# Load ground truth annotations\n",
    "GT_PATH = DATA_DIR / \"val.csv\"\n",
    "gt_df = pd.read_csv(GT_PATH)\n",
    "print(f\"\\nGround truth: {len(gt_df)} detections, {gt_df['track_id'].nunique()} tracks\")\n",
    "\n",
    "# Load SOTA predictions\n",
    "SOTA_PATH = DATA_DIR / \"sota.csv\"\n",
    "sota_df = pd.read_csv(SOTA_PATH)\n",
    "print(f\"SOTA predictions: {len(sota_df)} detections, {sota_df['track_id'].nunique()} tracks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TQ93FLf6SMXn",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "842732c57d10495896259becffc4c2c4",
      "c01f2042e7b1461aa92bed9c97678e62",
      "cfb8fa5b255e45b48dbc79f3d7e83b0e",
      "e73ac23291994dadba67df9f673960ad",
      "0f93ab45454b426285dbf98eb8f9b277",
      "9beb35c95a644c428d215ab4be129729",
      "325f5392785e47d293e7c7d7e5deebf5",
      "be2e7db2151e48cd855069c9acc0ba84",
      "d58c4c709ae84b388b9be03ac1714d0f",
      "2788d83a15ee4f72ae4dff6873eaba9b",
      "459a2e623a694b98822ae2b47a67f20e"
     ]
    },
    "outputId": "183a35a4-7509-41c6-9bf1-b7c01c38bcc1"
   },
   "outputs": [],
   "source": "# Run detection for both models\nprint(\"=\"*60)\nprint(\"Running Detection for Both StarDist Models\")\nprint(\"=\"*60)\n\n# StarDist (No Bonus)\nprint(\"\\n[1/2] StarDist (No Bonus)...\")\ndetections_nobonus_df, detections_nobonus_per_frame = run_detection(\n    video, models_nobonus, \n    config_nobonus['prob_thresh'], config_nobonus['nms_thresh'], \n    roi=ROI\n)\nprint(f\"  Detected {len(detections_nobonus_df)} cells ({len(detections_nobonus_df)/len(video):.1f}/frame)\")\n\n# StarDist (Original)\nprint(\"\\n[2/2] StarDist (Original)...\")\ndetections_original_df, detections_original_per_frame = run_detection(\n    video, models_original, \n    config_original['prob_thresh'], config_original['nms_thresh'], \n    roi=ROI\n)\nprint(f\"  Detected {len(detections_original_df)} cells ({len(detections_original_df)/len(video):.1f}/frame)\")\n\nprint(\"\\nDetection complete for both models.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc0Skb1HSMXn",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "56d3f237-f454-4550-c4f4-a09fd84c6851"
   },
   "outputs": [],
   "source": "# Run tracking for both models\nprint(\"=\"*60)\nprint(\"Running Tracking for Both StarDist Models\")\nprint(\"=\"*60)\n\n# StarDist (No Bonus)\nprint(\"\\n[1/2] Tracking StarDist (No Bonus)...\")\ntracks_nobonus_df = run_tracking(detections_nobonus_per_frame)\ntracks_nobonus_df['x'] += ROI['x_min']\ntracks_nobonus_df['y'] += ROI['y_min']\nprint(f\"  Found {tracks_nobonus_df['track_id'].nunique()} tracks\")\nprint(f\"  Avg track length: {tracks_nobonus_df.groupby('track_id').size().mean():.1f} frames\")\n\n# StarDist (Original)\nprint(\"\\n[2/2] Tracking StarDist (Original)...\")\ntracks_original_df = run_tracking(detections_original_per_frame)\ntracks_original_df['x'] += ROI['x_min']\ntracks_original_df['y'] += ROI['y_min']\nprint(f\"  Found {tracks_original_df['track_id'].nunique()} tracks\")\nprint(f\"  Avg track length: {tracks_original_df.groupby('track_id').size().mean():.1f} frames\")\n\nprint(\"\\nTracking complete for both models.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xwv9JMJpSMXn",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 832
    },
    "outputId": "f2ef56f4-d119-4df8-e80e-cdb4ec2691da"
   },
   "outputs": [],
   "source": "# Visual Comparison: GT vs StarDist (No Bonus) vs StarDist (Original) vs SOTA\nnum_frames = 6\nstart_frame = 0\ncols = 3\nrows = 2\n\nfig, axes = plt.subplots(rows, cols, figsize=(18, 12))\naxes = axes.flatten()\n\nfor i in range(num_frames):\n    frame_idx = start_frame + i\n    ax = axes[i]\n\n    # ROI crop\n    roi_frame = video[frame_idx, ROI['y_min']:ROI['y_max'], ROI['x_min']:ROI['x_max']]\n    ax.imshow(roi_frame, cmap='gray')\n\n    # Ground Truth (Green Circles)\n    gt_frame = gt_df[gt_df['frame'] == frame_idx]\n    if len(gt_frame) > 0:\n        ax.scatter(gt_frame['x'] - ROI['x_min'], gt_frame['y'] - ROI['y_min'],\n                   edgecolor='lime', s=100, marker='o', facecolors='none', linewidths=2, \n                   label='GT' if i==0 else \"\")\n\n    # StarDist (No Bonus) - Red X\n    nobonus_frame = detections_nobonus_df[detections_nobonus_df['frame'] == frame_idx]\n    if len(nobonus_frame) > 0:\n        ax.scatter(nobonus_frame['x'] - ROI['x_min'], nobonus_frame['y'] - ROI['y_min'],\n                   c='red', s=50, marker='x', linewidths=2, \n                   label='StarDist (No Bonus)' if i==0 else \"\")\n\n    # StarDist (Original) - Blue +\n    original_frame = detections_original_df[detections_original_df['frame'] == frame_idx]\n    if len(original_frame) > 0:\n        ax.scatter(original_frame['x'] - ROI['x_min'], original_frame['y'] - ROI['y_min'],\n                   c='dodgerblue', s=50, marker='+', linewidths=2, \n                   label='StarDist (Original)' if i==0 else \"\")\n\n    # SOTA - Yellow triangles\n    sota_frame = sota_df[sota_df['frame'] == frame_idx]\n    if len(sota_frame) > 0:\n        ax.scatter(sota_frame['x'] - ROI['x_min'], sota_frame['y'] - ROI['y_min'],\n                   edgecolor='yellow', s=60, marker='^', facecolors='none', linewidths=1.5, \n                   label='SOTA' if i==0 else \"\")\n\n    ax.set_title(f'Frame {frame_idx}', fontsize=12)\n    ax.axis('off')\n\n# Legend\nhandles, labels = axes[0].get_legend_handles_labels()\nif handles:\n    fig.legend(handles, labels, loc='upper center', ncol=4, fontsize=12, frameon=True, \n               bbox_to_anchor=(0.5, 0.98))\n\nplt.suptitle('Detection Comparison: All Methods', fontsize=14, y=1.0)\nplt.tight_layout()\nplt.subplots_adjust(top=0.9)\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "source": "---\n\n## 7. Evaluation Metrics\n\nCalculate HOTA, DetA, and AssA metrics for all three methods.",
   "metadata": {
    "id": "FTU07uS8JmMu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Evaluation metric functions\n",
    "def calculate_deta(gt_df, pred_df, match_thresh=5.0):\n",
    "    \"\"\"Calculate Detection Accuracy (DetA) using Hungarian matching.\"\"\"\n",
    "    gt_df = gt_df.copy()\n",
    "    pred_df = pred_df.copy()\n",
    "    gt_df['frame'] = gt_df['frame'].astype(int)\n",
    "    pred_df['frame'] = pred_df['frame'].astype(int)\n",
    "\n",
    "    total_tp, total_fp, total_fn = 0, 0, 0\n",
    "\n",
    "    for frame in gt_df['frame'].unique():\n",
    "        gt_frame = gt_df[gt_df['frame'] == frame][['x', 'y']].values\n",
    "        pred_frame = pred_df[pred_df['frame'] == frame][['x', 'y']].values\n",
    "\n",
    "        if len(gt_frame) == 0:\n",
    "            total_fp += len(pred_frame)\n",
    "            continue\n",
    "        if len(pred_frame) == 0:\n",
    "            total_fn += len(gt_frame)\n",
    "            continue\n",
    "\n",
    "        dist_matrix = spatial.distance.cdist(gt_frame, pred_frame)\n",
    "        row_ind, col_ind = linear_sum_assignment(dist_matrix)\n",
    "        matches = sum(dist_matrix[row_ind[i], col_ind[i]] <= match_thresh for i in range(len(row_ind)))\n",
    "\n",
    "        total_tp += matches\n",
    "        total_fp += len(pred_frame) - matches\n",
    "        total_fn += len(gt_frame) - matches\n",
    "\n",
    "    deta = total_tp / max(1, total_tp + total_fp + total_fn)\n",
    "    return deta, {'TP': total_tp, 'FP': total_fp, 'FN': total_fn}\n",
    "\n",
    "\n",
    "def hota(gt: pd.DataFrame, tr: pd.DataFrame, threshold: float = 5) -> dict:\n",
    "    \"\"\"Calculate HOTA (Higher Order Tracking Accuracy) metric.\"\"\"\n",
    "    gt = gt.copy()\n",
    "    tr = tr.copy()\n",
    "\n",
    "    if 'track_id' not in gt.columns or 'track_id' not in tr.columns:\n",
    "        return {'HOTA': 0.0, 'AssA': 0.0, 'DetA': 0.0}\n",
    "    if gt.empty or tr.empty:\n",
    "        return {'HOTA': 0.0, 'AssA': 0.0, 'DetA': 0.0}\n",
    "\n",
    "    gt.track_id = gt.track_id.map({old: new for old, new in zip(gt.track_id.unique(), range(gt.track_id.nunique()))})\n",
    "    tr.track_id = tr.track_id.map({old: new for old, new in zip(tr.track_id.unique(), range(tr.track_id.nunique()))})\n",
    "\n",
    "    num_gt_ids = gt.track_id.nunique()\n",
    "    num_tr_ids = tr.track_id.nunique()\n",
    "\n",
    "    matches_count = np.zeros((num_gt_ids, num_tr_ids))\n",
    "    gt_id_count = np.zeros((num_gt_ids, 1))\n",
    "    tracker_id_count = np.zeros((1, num_tr_ids))\n",
    "    HOTA_TP = HOTA_FN = HOTA_FP = 0\n",
    "\n",
    "    similarities = [1 - np.clip(spatial.distance.cdist(\n",
    "        gt[gt.frame == t][['x', 'y']].values,\n",
    "        tr[tr.frame == t][['x', 'y']].values\n",
    "    ) / threshold, 0, 1) for t in range(int(gt.frame.max()) + 1)]\n",
    "\n",
    "    for t in range(int(gt.frame.max()) + 1):\n",
    "        gt_ids_t = gt[gt.frame == t].track_id.to_numpy()\n",
    "        tr_ids_t = tr[tr.frame == t].track_id.to_numpy()\n",
    "\n",
    "        gt_id_count[gt_ids_t] += 1\n",
    "        tracker_id_count[:, tr_ids_t] += 1\n",
    "\n",
    "        if len(gt_ids_t) == 0:\n",
    "            HOTA_FP += len(tr_ids_t)\n",
    "            continue\n",
    "        if len(tr_ids_t) == 0:\n",
    "            HOTA_FN += len(gt_ids_t)\n",
    "            continue\n",
    "\n",
    "        similarity = similarities[t]\n",
    "        match_rows, match_cols = linear_sum_assignment(-similarity)\n",
    "        mask = similarity[match_rows, match_cols] > 0\n",
    "        alpha_match_rows = match_rows[mask]\n",
    "        alpha_match_cols = match_cols[mask]\n",
    "        num_matches = len(alpha_match_rows)\n",
    "\n",
    "        HOTA_TP += num_matches\n",
    "        HOTA_FN += len(gt_ids_t) - num_matches\n",
    "        HOTA_FP += len(tr_ids_t) - num_matches\n",
    "\n",
    "        if num_matches > 0:\n",
    "            matches_count[gt_ids_t[alpha_match_rows], tr_ids_t[alpha_match_cols]] += 1\n",
    "\n",
    "    ass_a = matches_count / np.maximum(1, gt_id_count + tracker_id_count - matches_count)\n",
    "    AssA = np.sum(matches_count * ass_a) / np.maximum(1, HOTA_TP)\n",
    "    DetA = HOTA_TP / np.maximum(1, HOTA_TP + HOTA_FN + HOTA_FP)\n",
    "    HOTA_score = np.sqrt(DetA * AssA)\n",
    "\n",
    "    return {'HOTA': float(HOTA_score), 'AssA': float(AssA), 'DetA': float(DetA)}\n",
    "\n",
    "print(\"Evaluation functions defined.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vVi1u5iIJmMv",
    "outputId": "49cd8bb3-dbfa-473d-fcde-df7fac6d5737"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Evaluation functions defined.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": "# Calculate metrics for all three methods\nprint(\"=\"*70)\nprint(\"COMPUTING HOTA METRICS FOR ALL METHODS\")\nprint(\"=\"*70)\n\n# StarDist (No Bonus)\nprint(\"\\n[1/3] StarDist (No Bonus)...\")\nhota_nobonus = hota(gt_df, tracks_nobonus_df)\nprint(f\"  HOTA={hota_nobonus['HOTA']:.4f}, DetA={hota_nobonus['DetA']:.4f}, AssA={hota_nobonus['AssA']:.4f}\")\n\n# StarDist (Original)\nprint(\"\\n[2/3] StarDist (Original)...\")\nhota_original = hota(gt_df, tracks_original_df)\nprint(f\"  HOTA={hota_original['HOTA']:.4f}, DetA={hota_original['DetA']:.4f}, AssA={hota_original['AssA']:.4f}\")\n\n# SOTA\nprint(\"\\n[3/3] SOTA...\")\nhota_sota = hota(gt_df, sota_df)\nprint(f\"  HOTA={hota_sota['HOTA']:.4f}, DetA={hota_sota['DetA']:.4f}, AssA={hota_sota['AssA']:.4f}\")\n\nprint(\"\\nMetric computation complete.\")\n\n# ============================================================\n# FINAL COMPARISON TABLE\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL COMPARISON TABLE\")\nprint(\"=\"*70)\n\ncomparison_df = pd.DataFrame({\n    'Method': ['StarDist (No Bonus)', 'StarDist (Original)', 'SOTA'],\n    'DetA': [hota_nobonus['DetA'], hota_original['DetA'], hota_sota['DetA']],\n    'AssA': [hota_nobonus['AssA'], hota_original['AssA'], hota_sota['AssA']],\n    'HOTA': [hota_nobonus['HOTA'], hota_original['HOTA'], hota_sota['HOTA']],\n    'Tracks': [tracks_nobonus_df['track_id'].nunique(), \n               tracks_original_df['track_id'].nunique(), \n               sota_df['track_id'].nunique()],\n    'Detections': [len(tracks_nobonus_df), len(tracks_original_df), len(sota_df)]\n})\n\n# Sort by HOTA (best first)\ncomparison_df = comparison_df.sort_values('HOTA', ascending=False).reset_index(drop=True)\n\n# Display formatted table\nprint(\"\\n\" + comparison_df.to_string(index=False, float_format=lambda x: f\"{x:.4f}\" if isinstance(x, float) else str(x)))\n\n# Ground truth reference\nprint(f\"\\n[Ground Truth: {gt_df['track_id'].nunique()} tracks, {len(gt_df)} detections]\")\n\n# Highlight best method\nbest_method = comparison_df.iloc[0]['Method']\nbest_hota = comparison_df.iloc[0]['HOTA']\nprint(f\"\\nBest Method: {best_method} (HOTA = {best_hota:.4f})\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 971
    },
    "id": "2jSiMomxJmMv",
    "outputId": "04109a93-8295-4a43-ff48-0d54a6c438a2"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2fp62MuHSMXo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "465b4fb3-7d1f-4bcb-8ad6-2ee8627ec733"
   },
   "outputs": [],
   "source": "# Bar chart comparison of all 3 methods\nfig, ax = plt.subplots(figsize=(12, 6))\n\nmetrics = ['DetA', 'AssA', 'HOTA']\nx = np.arange(len(metrics))\nwidth = 0.25\n\n# Get values in original order\nmethods_data = {\n    'StarDist (No Bonus)': hota_nobonus,\n    'StarDist (Original)': hota_original,\n    'SOTA': hota_sota\n}\ncolors = ['steelblue', 'coral', 'forestgreen']\n\nbars = []\nfor i, (method, data) in enumerate(methods_data.items()):\n    values = [data[m] for m in metrics]\n    bar = ax.bar(x + (i - 1) * width, values, width, label=method, color=colors[i])\n    bars.append(bar)\n\nax.set_ylabel('Score', fontsize=12)\nax.set_title('Performance Comparison: DetA, AssA, HOTA', fontsize=14)\nax.set_xticks(x)\nax.set_xticklabels(metrics, fontsize=12)\nax.legend(fontsize=11)\nax.set_ylim(0, 1)\nax.grid(axis='y', alpha=0.3)\n\n# Add value labels on bars\nfor bar_group in bars:\n    for bar in bar_group:\n        height = bar.get_height()\n        ax.annotate(f'{height:.3f}',\n                    xy=(bar.get_x() + bar.get_width() / 2, height),\n                    xytext=(0, 3), textcoords='offset points',\n                    ha='center', va='bottom', fontsize=9)\n\nplt.tight_layout()\nplt.show()\n\n# ============================================================\n# Display styled comparison table\n# ============================================================\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL RESULTS TABLE\")\nprint(\"=\"*70 + \"\\n\")\n\n# Create nicely formatted display table\ndisplay_df = comparison_df.copy()\ndisplay_df['DetA'] = display_df['DetA'].apply(lambda x: f\"{x:.4f}\")\ndisplay_df['AssA'] = display_df['AssA'].apply(lambda x: f\"{x:.4f}\")\ndisplay_df['HOTA'] = display_df['HOTA'].apply(lambda x: f\"{x:.4f}\")\n\nprint(display_df.to_markdown(index=False))\nprint(\"\\n\" + \"=\"*70)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2ohlJ-QSMXo"
   },
   "source": "---\n\n## Summary\n\nThis notebook compares **3 cell detection methods** on the TIRF-SIM validation dataset:\n\n| Method | Description |\n|--------|-------------|\n| **StarDist (No Bonus)** | 100 epochs, 64 rays, NMS=0.2, trained without bonus data |\n| **StarDist (Original)** | 100 epochs, 64 rays, NMS=0.35, trained with bonus data |\n| **SOTA** | State-of-the-art baseline from competition |\n\n### Pipeline:\n1. Load model weights from local `ansamble_weights/` directory (or GitHub for Colab)\n2. Load test data from Google Drive (val.tif, val.csv, sota.csv)\n3. Run cell detection with both StarDist models\n4. Run **LapTrack** tracking on detections\n5. Compare all methods using **HOTA, DetA, AssA** metrics\n\n### Metrics Explained:\n- **DetA** (Detection Accuracy): Measures detection quality per frame\n- **AssA** (Association Accuracy): Measures track association quality\n- **HOTA** (Higher Order Tracking Accuracy): Geometric mean of DetA and AssA\n\nFor questions or issues, see: https://github.com/veselm73/SU2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "a6e5da9b8d1e4390b628cb7bd2e4e1f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3f4807acdc741948d54079c93ead2e7",
       "IPY_MODEL_2d3623916ca446298c4707e65154a8c6",
       "IPY_MODEL_7bf6124f51b845ebb60040c311aab414"
      ],
      "layout": "IPY_MODEL_08e29a9975cf440fb8ec83ce1606dcea"
     }
    },
    "d3f4807acdc741948d54079c93ead2e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c9e552abde34ba89fb74e61633e7442",
      "placeholder": "​",
      "style": "IPY_MODEL_b9f189b19a2e4e6588ead99c9c9b5f20",
      "value": "model.safetensors: 100%"
     }
    },
    "2d3623916ca446298c4707e65154a8c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b9563ab05de4acd9340f034b3359034",
      "max": 46807446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b3cc356e9b8b4157a0d72d7720f8d59c",
      "value": 46807446
     }
    },
    "7bf6124f51b845ebb60040c311aab414": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33ef163ddbbd4c459dc8cf281428fe66",
      "placeholder": "​",
      "style": "IPY_MODEL_4dec0b51260d4a07a2b59a23a9b2cc65",
      "value": " 46.8M/46.8M [00:00&lt;00:00, 74.8MB/s]"
     }
    },
    "08e29a9975cf440fb8ec83ce1606dcea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c9e552abde34ba89fb74e61633e7442": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9f189b19a2e4e6588ead99c9c9b5f20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b9563ab05de4acd9340f034b3359034": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3cc356e9b8b4157a0d72d7720f8d59c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "33ef163ddbbd4c459dc8cf281428fe66": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4dec0b51260d4a07a2b59a23a9b2cc65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "842732c57d10495896259becffc4c2c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c01f2042e7b1461aa92bed9c97678e62",
       "IPY_MODEL_cfb8fa5b255e45b48dbc79f3d7e83b0e",
       "IPY_MODEL_e73ac23291994dadba67df9f673960ad"
      ],
      "layout": "IPY_MODEL_0f93ab45454b426285dbf98eb8f9b277"
     }
    },
    "c01f2042e7b1461aa92bed9c97678e62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9beb35c95a644c428d215ab4be129729",
      "placeholder": "​",
      "style": "IPY_MODEL_325f5392785e47d293e7c7d7e5deebf5",
      "value": "Detecting: 100%"
     }
    },
    "cfb8fa5b255e45b48dbc79f3d7e83b0e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be2e7db2151e48cd855069c9acc0ba84",
      "max": 722,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d58c4c709ae84b388b9be03ac1714d0f",
      "value": 722
     }
    },
    "e73ac23291994dadba67df9f673960ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2788d83a15ee4f72ae4dff6873eaba9b",
      "placeholder": "​",
      "style": "IPY_MODEL_459a2e623a694b98822ae2b47a67f20e",
      "value": " 722/722 [01:43&lt;00:00,  7.54it/s]"
     }
    },
    "0f93ab45454b426285dbf98eb8f9b277": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9beb35c95a644c428d215ab4be129729": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "325f5392785e47d293e7c7d7e5deebf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "be2e7db2151e48cd855069c9acc0ba84": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d58c4c709ae84b388b9be03ac1714d0f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2788d83a15ee4f72ae4dff6873eaba9b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "459a2e623a694b98822ae2b47a67f20e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}