{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "22365585",
      "metadata": {},
      "source": [
        "# SU2 Project - Unet++ Training (VS Code Ready)\n",
        "\n",
        "This notebook runs the training pipeline directly from this repository. It stores artifacts locally so it plays nicely with VS Code Jupyter (local Python or the Colab extension) without requiring a Google Drive mount.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "30871456",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository root: /content\n",
            "Artifacts will be stored in: /content/artifacts\n",
            "Checkpoints directory: /content/checkpoints\n",
            "Validation data directory: /content/val_data\n"
          ]
        }
      ],
      "source": [
        "# Workspace paths (no Google Drive dependency)\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "IS_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "REPO_ROOT = Path(os.environ.get('SU2_REPO_ROOT', Path.cwd())).resolve()\n",
        "if not REPO_ROOT.exists():\n",
        "    raise FileNotFoundError(f\"Configured REPO_ROOT does not exist: {REPO_ROOT}\")\n",
        "\n",
        "os.chdir(REPO_ROOT)\n",
        "\n",
        "SAVE_DIR = Path(os.environ.get('SU2_SAVE_DIR', REPO_ROOT / 'artifacts'))\n",
        "CHECKPOINT_DIR = Path(os.environ.get('SU2_CHECKPOINT_DIR', REPO_ROOT / 'checkpoints'))\n",
        "VAL_DATA_DIR = Path(os.environ.get('SU2_VAL_DATA_DIR', REPO_ROOT / 'val_data'))\n",
        "CHAIN_PATH = Path(os.environ.get('SU2_CERT_CHAIN', REPO_ROOT / 'chain-harica-cross.pem'))\n",
        "\n",
        "for path in (SAVE_DIR, CHECKPOINT_DIR, VAL_DATA_DIR):\n",
        "    path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(f\"Repository root: {REPO_ROOT}\")\n",
        "print(f\"Artifacts will be stored in: {SAVE_DIR}\")\n",
        "print(f\"Checkpoints directory: {CHECKPOINT_DIR}\")\n",
        "print(f\"Validation data directory: {VAL_DATA_DIR}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "efa8d561",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration saved to config.yaml\n"
          ]
        }
      ],
      "source": [
        "# Define Configuration\n",
        "# You can modify these values directly here before running the training\n",
        "config_content = \"\"\"\n",
        "TRAIN_SAMPLES: 5000\n",
        "VAL_SAMPLES: 800\n",
        "BATCH_SIZE: 16             # Reduced from 32 (more frequent updates, fits T4 memory)\n",
        "LEARNING_RATE: 5e-4\n",
        "WEIGHT_DECAY: 1e-4\n",
        "DROPOUT_RATE: 0.15\n",
        "EPOCHS: 300\n",
        "PATIENCE: 15\n",
        "SEED: 73\n",
        "\n",
        "# Detection Model Configuration\n",
        "DETECTION_MODEL: \"sam3\"  # Options: \"unet\", \"sam3\"\n",
        "SAM3_CHECKPOINT: \"checkpoints/sam3.pt\"\n",
        "SKIP_TRAINING: True # Set to True to skip UNet++ training and just use SAM 3\n",
        "\n",
        "# Detection Model Configuration\n",
        "DETECTION_MODEL: \"sam3\"  # Options: \"unet\", \"sam3\"\n",
        "SAM3_CHECKPOINT: \"checkpoints/sam3_hiera_large.pt\"\n",
        "SAM3_MODEL_TYPE: \"vit_l\"\n",
        "\n",
        "# Data Generator Config\n",
        "MIN_CELLS: 8\n",
        "MAX_CELLS: 24\n",
        "PATCH_SIZE: 128\n",
        "SIM_CONFIG:\n",
        "  na: 1.49\n",
        "  wavelength: 512\n",
        "  px_size: 0.07\n",
        "  wiener_parameter: 0.1\n",
        "  apo_cutoff: 2.0\n",
        "  apo_bend: 0.9\n",
        "\"\"\"\n",
        "\n",
        "with open(\"config.yaml\", \"w\") as f:\n",
        "    f.write(config_content)\n",
        "\n",
        "print(\"Configuration saved to config.yaml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5b0b013e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing dependencies... (This may take a few minutes)\n",
            "Install complete. Restart the kernel only if VS Code prompts you to reload modules.\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies with restart-safe workflow\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "\n",
        "def pip_install(*packages):\n",
        "    subprocess.check_call([sys.executable, '-m', 'pip', 'install', *packages])\n",
        "\n",
        "\n",
        "try:\n",
        "    import btrack\n",
        "    import sam3\n",
        "    print('Dependencies already installed.')\n",
        "except ImportError:\n",
        "    print('Installing dependencies... (This may take a few minutes)')\n",
        "    pip_install('btrack==0.6.5', 'pydantic<2', 'pyyaml')\n",
        "    pip_install('git+https://github.com/facebookresearch/sam3.git')\n",
        "    pip_install('einops', 'decord', 'pycocotools', 'scipy')\n",
        "    print('Install complete. Restart the kernel only if VS Code prompts you to reload modules.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "1fc5911b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAM 3 checkpoint missing. Please place it at: /content/checkpoints/sam3_hiera_large.pt\n"
          ]
        }
      ],
      "source": [
        "# Check for SAM 3 checkpoint\n",
        "CHECKPOINT_PATH = CHECKPOINT_DIR / 'sam3_hiera_large.pt'\n",
        "\n",
        "if not CHECKPOINT_PATH.exists():\n",
        "    print(f\"SAM 3 checkpoint missing. Please place it at: {CHECKPOINT_PATH}\")\n",
        "else:\n",
        "    print(f\"Checkpoint found at {CHECKPOINT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d1d632e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "if str(REPO_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "import modules.config\n",
        "importlib.reload(modules.config)\n",
        "\n",
        "from modules.config import *\n",
        "from modules.utils import set_seed, plot_training_history\n",
        "from modules.training import train_unet_pipeline\n",
        "from modules.tracking import run_tracking_on_validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24a6ff21",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set random seeds\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf94aab6",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'SKIP_TRAINING' not in globals() or not SKIP_TRAINING:\n",
        "    # Run Training Pipeline\n",
        "    print(\"Starting Training Pipeline...\")\n",
        "    model, history = train_unet_pipeline(\n",
        "        train_samples=TRAIN_SAMPLES,\n",
        "        val_samples=VAL_SAMPLES,\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        learning_rate=LEARNING_RATE,\n",
        "        weight_decay=WEIGHT_DECAY,\n",
        "        patience=PATIENCE,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "else:\n",
        "    print(\"Skipping UNet++ training (SKIP_TRAINING=True)\")\n",
        "    model = None\n",
        "    history = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9d4ddda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot History\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd604fe6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save model locally\n",
        "import shutil\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "if model is None:\n",
        "    print('SKIP_TRAINING=True so there is no trained UNet++ model to save.')\n",
        "else:\n",
        "    save_path = SAVE_DIR / 'final_model.pth'\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "    best_model_path = Path('best_model.pth')\n",
        "    if best_model_path.exists():\n",
        "        best_save_path = SAVE_DIR / 'best_model.pth'\n",
        "        shutil.copy(best_model_path, best_save_path)\n",
        "        print(f\"Best model saved to {best_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d5d36c",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download validation data (stored locally)\n",
        "from modules.utils import download_and_unzip\n",
        "import requests\n",
        "\n",
        "print('1) Downloading SSL certificate chain...')\n",
        "cert_url = 'https://pki.cesnet.cz/_media/certs/chain-harica-rsa-ov-crosssigned-root.pem'\n",
        "response = requests.get(cert_url, timeout=10, stream=True)\n",
        "response.raise_for_status()\n",
        "CHAIN_PATH.write_bytes(response.content)\n",
        "print('2) Certificate chain downloaded.\n",
        "')\n",
        "\n",
        "zip_url = 'https://su2.utia.cas.cz/files/labs/final2025/val_and_sota.zip'\n",
        "download_and_unzip(zip_url, str(VAL_DATA_DIR), str(CHAIN_PATH))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab177d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define Parameter Grids for Sweep\n",
        "from modules.tracking import DetectionParams, BTrackParams\n",
        "\n",
        "# 1. Detection: High Recall (0.25 - 0.30)\n",
        "det_param_grid = {\n",
        "    \"threshold\": [0.25, 0.3],\n",
        "    \"min_area\": [4],\n",
        "    \"nms_min_dist\": [3.0]\n",
        "}\n",
        "\n",
        "# 2. Tracking: Optimize + Aggressive Filtering\n",
        "btrack_param_grid = {\n",
        "    \"do_optimize\": [False],              # Enable Global Optimization\n",
        "    \"max_search_radius\": [20.0],\n",
        "    \"dist_thresh\": [15.0],\n",
        "    \"time_thresh\": [4, 6],              # Allow gaps\n",
        "    \"min_track_len\": [10, 15],          # Filter noise from low threshold\n",
        "    \"segmentation_miss_rate\": [0.1],\n",
        "    \"apoptosis_rate\": [0.001],\n",
        "    \"allow_divisions\": [False]\n",
        "}\n",
        "\n",
        "print(\"Parameter grids defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39dbe7d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run tracking sweep and generate GIF\n",
        "from modules.sweep import sweep_and_save_gif\n",
        "\n",
        "val_tif_path = (VAL_DATA_DIR / 'val.tif').resolve()\n",
        "gif_output_path = SAVE_DIR / 'best_tracking.gif'\n",
        "\n",
        "best_det, best_bt, best_tracks = sweep_and_save_gif(\n",
        "    model,\n",
        "    det_param_grid,\n",
        "    btrack_param_grid,\n",
        "    gif_output=str(gif_output_path),\n",
        "    val_tif_path=str(val_tif_path)\n",
        ")\n",
        "\n",
        "print(f\"Best tracking GIF saved to: {gif_output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838033e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize SAM 3 predictions vs ground truth (image + mask)\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from modules.sam_detector import SAM3Detector\n",
        "from modules.utils import open_tiff_file\n",
        "\n",
        "print('Visualizing SAM 3 predictions...')\n",
        "\n",
        "val_tif_path = VAL_DATA_DIR / 'val.tif'\n",
        "if val_tif_path.exists():\n",
        "    val_images = open_tiff_file(str(val_tif_path))\n",
        "    sample_image = val_images[0]\n",
        "\n",
        "    detector = SAM3Detector()\n",
        "    if detector.model is not None:\n",
        "        mask, detections = detector.detect(sample_image, text_prompt='cell')\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(sample_image, cmap='gray')\n",
        "        plt.title('Input Image')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title('SAM 3 Prediction')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(sample_image, cmap='gray')\n",
        "        plt.imshow(mask, alpha=0.5, cmap='jet')\n",
        "        plt.title('Overlay')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('SAM 3 model not loaded.')\n",
        "else:\n",
        "    print('Validation data not found. Please run the download cell first.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e579315f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize SAM 3 predictions with GT overlay\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from modules.sam_detector import SAM3Detector\n",
        "from modules.utils import open_tiff_file\n",
        "\n",
        "print('Visualizing SAM 3 predictions...')\n",
        "\n",
        "val_tif_path = VAL_DATA_DIR / 'val.tif'\n",
        "val_csv_path = VAL_DATA_DIR / 'val.csv'\n",
        "\n",
        "if val_tif_path.exists():\n",
        "    val_images = open_tiff_file(str(val_tif_path))\n",
        "    sample_idx = 0\n",
        "    sample_image = val_images[sample_idx]\n",
        "\n",
        "    detector = SAM3Detector()\n",
        "    if detector.model is not None:\n",
        "        mask, detections = detector.detect(sample_image, text_prompt='cell')\n",
        "\n",
        "        gt_mask = np.zeros_like(mask)\n",
        "        if val_csv_path.exists():\n",
        "            df = pd.read_csv(val_csv_path)\n",
        "            frame_df = df[df['frame'] == sample_idx]\n",
        "            for _, row in frame_df.iterrows():\n",
        "                y, x = int(row['y']), int(row['x'])\n",
        "                if 0 <= y < gt_mask.shape[0] and 0 <= x < gt_mask.shape[1]:\n",
        "                    gt_mask[max(0, y-2):min(gt_mask.shape[0], y+3), max(0, x-2):min(gt_mask.shape[1], x+3)] = 1\n",
        "\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.subplot(1, 4, 1)\n",
        "        plt.imshow(sample_image, cmap='gray')\n",
        "        plt.title('Input Image')\n",
        "\n",
        "        plt.subplot(1, 4, 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title('SAM 3 Prediction')\n",
        "\n",
        "        plt.subplot(1, 4, 3)\n",
        "        plt.imshow(gt_mask, cmap='gray')\n",
        "        plt.title('Ground Truth (Approx)')\n",
        "\n",
        "        plt.subplot(1, 4, 4)\n",
        "        plt.imshow(sample_image, cmap='gray')\n",
        "        plt.imshow(mask, alpha=0.4, cmap='jet')\n",
        "        plt.imshow(gt_mask, alpha=0.4, cmap='spring')\n",
        "        plt.title('Overlay (SAM=Jet, GT=Pink)')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print('SAM 3 model not loaded.')\n",
        "else:\n",
        "    print('Validation data not found. Please run the download cell first.')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
