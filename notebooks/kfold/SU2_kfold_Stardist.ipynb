{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00da1c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q cellseg-models-pytorch pytorch-lightning \"btrack==0.6.5\" \"laptrack\" \"pydantic<2\" \"albumentations==1.3.1\" \"numpy<2\" opencv-python-headless pandas scipy scikit-image scikit-learn matplotlib seaborn tqdm ipywidgets tifffile numba\n",
    "# Uninstall TensorFlow to avoid conflicts (if any)\n",
    "!pip uninstall -y tensorflow tensorflow-intel tensorflow-cpu stardist csbdeep || true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d117a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import random\n",
    "import math\n",
    "import warnings\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.draw import disk\n",
    "from sklearn.model_selection import KFold\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# PyTorch & Lightning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# StarDist (PyTorch)\n",
    "try:\n",
    "    from cellseg_models_pytorch.models.stardist.stardist import StarDist\n",
    "    from cellseg_models_pytorch.transforms.functional.stardist import gen_stardist_maps\n",
    "    from cellseg_models_pytorch.postproc.functional.stardist.stardist import post_proc_stardist\n",
    "    print(\"StarDist (PyTorch) libraries imported successfully.\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing cellseg-models-pytorch: {e}\")\n",
    "    # Fallback/Exit handled by installation cell usually\n",
    "\n",
    "# Tracking\n",
    "try:\n",
    "    import btrack\n",
    "    print(f\"btrack version: {btrack.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"btrack not found.\")\n",
    "    btrack = None\n",
    "\n",
    "try:\n",
    "    import laptrack\n",
    "    from laptrack import LapTrack\n",
    "    print(f\"laptrack version: {laptrack.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"laptrack not found.\")\n",
    "    laptrack = None\n",
    "\n",
    "# --- Constants ---\n",
    "ROI_Y_MIN, ROI_Y_MAX = 512, 768\n",
    "ROI_X_MIN, ROI_X_MAX = 256, 512\n",
    "ROI_H, ROI_W = ROI_Y_MAX - ROI_Y_MIN, ROI_X_MAX - ROI_X_MIN\n",
    "\n",
    "N_RAYS = 32\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 20  # Adjust as needed\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {DEVICE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf422be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_validation_data(target_dir: str = \"val_data\",\n",
    "                             url: str = \"https://su2.utia.cas.cz/files/labs/final2025/val_and_sota.zip\",\n",
    "                             cert_url: str = \"https://pki.cesnet.cz/_media/certs/chain-harica-rsa-ov-crosssigned-root.pem\"):\n",
    "    if os.path.exists(target_dir) and len(os.listdir(target_dir)) > 0:\n",
    "        print(f\"'{target_dir}' already exists. Skipping download.\")\n",
    "        return\n",
    "\n",
    "    chain_path = \"chain-harica-cross.pem\"\n",
    "    print(\"1) Downloading SSL certificate chain...\")\n",
    "    try:\n",
    "        r = requests.get(cert_url, timeout=10, stream=True)\n",
    "        r.raise_for_status()\n",
    "        with open(chain_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not download cert chain ({e}), trying without...\")\n",
    "        chain_path = None\n",
    "\n",
    "    print(\"2) Downloading validation archive...\")\n",
    "    zip_name = os.path.basename(url)\n",
    "    \n",
    "    verify = chain_path if chain_path else False\n",
    "    \n",
    "    with requests.get(url, stream=True, verify=verify, timeout=30) as resp:\n",
    "        resp.raise_for_status()\n",
    "        with open(zip_name, \"wb\") as f:\n",
    "            for chunk in resp.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    \n",
    "    print(\"3) Extracting...\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    with zipfile.ZipFile(zip_name, \"r\") as zf:\n",
    "        zf.extractall(target_dir)\n",
    "    if os.path.exists(zip_name):\n",
    "        os.remove(zip_name)\n",
    "    print(f\"Done. Data in '{target_dir}/'\")\n",
    "\n",
    "# Download data\n",
    "download_validation_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare 'experiment_dataset' with StarDist mask style (label images)\n",
    "def create_stardist_label_mask(image_shape: Tuple[int, int], points, radius: int = 6) -> np.ndarray:\n",
    "    '''Convert center points into a StarDist-ready integer mask (instance labeled).'''\n",
    "    label_mask = np.zeros(image_shape, dtype=np.uint16)\n",
    "    current_id = 1\n",
    "    for (y, x) in points:\n",
    "        if y < 0 or x < 0 or y >= image_shape[0] or x >= image_shape[1]:\n",
    "            continue\n",
    "        rr, cc = disk((y, x), radius, shape=image_shape)\n",
    "        label_mask[rr, cc] = current_id\n",
    "        current_id += 1\n",
    "    return label_mask\n",
    "\n",
    "def _load_mask_image(path: Path) -> np.ndarray:\n",
    "    if path.suffix.lower() in {'.tif', '.tiff'}:\n",
    "        mask = tifffile.imread(path)\n",
    "    else:\n",
    "        mask = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "    if mask is None:\n",
    "        raise FileNotFoundError(f\"Missing mask: {path}\")\n",
    "    if mask.ndim == 3:\n",
    "        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    return mask\n",
    "\n",
    "def _label_connected(mask: np.ndarray) -> np.ndarray:\n",
    "    return label(mask > 0).astype(np.uint16)\n",
    "\n",
    "def prepare_grand_dataset(\n",
    "    real_data_dir: str = \"real_training_data\",\n",
    "    val_tif_path: str = \"val_data/val.tif\",\n",
    "    val_csv_path: str = \"val_data/val.csv\",\n",
    "    out_dir: str = \"experiment_dataset\",\n",
    "    roi_y: Tuple[int, int] = (ROI_Y_MIN, ROI_Y_MAX),\n",
    "    roi_x: Tuple[int, int] = (ROI_X_MIN, ROI_X_MAX),\n",
    "    disk_radius: int = 6,\n",
    ") -> Path:\n",
    "    out_path = Path(out_dir)\n",
    "    bonus_images = out_path / \"bonus\" / \"images\"\n",
    "    bonus_masks = out_path / \"bonus\" / \"masks\"\n",
    "    video_images = out_path / \"video\" / \"images\"\n",
    "    video_masks = out_path / \"video\" / \"masks\"\n",
    "\n",
    "    if out_path.exists():\n",
    "        shutil.rmtree(out_path)\n",
    "    for p in [bonus_images, bonus_masks, video_images, video_masks]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1. Real Bonus Data\n",
    "    src_images = Path(real_data_dir) / \"images\"\n",
    "    src_masks = Path(real_data_dir) / \"masks\"\n",
    "    if src_images.exists() and src_masks.exists():\n",
    "        print(\"Processing real training data (bonus)...\")\n",
    "        mask_lookup = {m.stem: m for m in src_masks.glob(\"*\")}\n",
    "        for img_path in sorted(src_images.glob(\"*\")):\n",
    "            shutil.copy(img_path, bonus_images / img_path.name)\n",
    "            # Find corresponding mask\n",
    "            expected_mask_stem = f\"{img_path.stem}_mask\"\n",
    "            if expected_mask_stem not in mask_lookup:\n",
    "                 # Fallback try exact match\n",
    "                 expected_mask_stem = img_path.stem\n",
    "            \n",
    "            if expected_mask_stem in mask_lookup:\n",
    "                mask_path = mask_lookup[expected_mask_stem]\n",
    "                bonus_mask_raw = _load_mask_image(mask_path)\n",
    "                # Convert binary to instance label\n",
    "                instance_mask = _label_connected(bonus_mask_raw)\n",
    "                tifffile.imwrite(bonus_masks / f\"{img_path.stem}.tif\", instance_mask)\n",
    "            else:\n",
    "                print(f\"Warning: No mask found for {img_path.name}\")\n",
    "    else:\n",
    "        print(f\"Note: '{real_data_dir}' not found. Skipping bonus data.\")\n",
    "\n",
    "    # 2. Validation Video Data\n",
    "    if Path(val_tif_path).exists() and Path(val_csv_path).exists():\n",
    "        print(\"Processing validation video data...\")\n",
    "        video = tifffile.imread(val_tif_path)\n",
    "        coords = pd.read_csv(val_csv_path)\n",
    "        y_min, y_max = roi_y\n",
    "        x_min, x_max = roi_x\n",
    "        records = []\n",
    "        \n",
    "        for idx, frame in enumerate(video):\n",
    "            crop = frame[y_min:y_max, x_min:x_max]\n",
    "            # Get points for this frame\n",
    "            frame_coords = coords[coords['frame'] == idx]\n",
    "            points = [(int(row['y'] - y_min), int(row['x'] - x_min)) for _, row in frame_coords.iterrows()]\n",
    "            \n",
    "            mask = create_stardist_label_mask((ROI_H, ROI_W), points, radius=disk_radius)\n",
    "            \n",
    "            video_images_idx_path = video_images / f\"frame_{idx:03d}.png\"\n",
    "            video_masks_idx_path = video_masks / f\"frame_{idx:03d}.tif\"\n",
    "            \n",
    "            cv2.imwrite(str(video_images_idx_path), crop)\n",
    "            tifffile.imwrite(str(video_masks_idx_path), mask)\n",
    "            records.append({\n",
    "                'filename': video_images_idx_path.name,\n",
    "                'real_frame_idx': idx\n",
    "            })\n",
    "            \n",
    "        video_map_df = pd.DataFrame(records)\n",
    "        video_map_df.to_csv(out_path / \"video_map.csv\", index=False)\n",
    "        print(f\"Processed {len(video)} video frames.\")\n",
    "    else:\n",
    "        print(\"Validation data not found.\")\n",
    "\n",
    "    return out_path\n",
    "\n",
    "# Execute Preparation\n",
    "OUT_DIR = prepare_grand_dataset()\n",
    "print(f\"Dataset ready at {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad5fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_gray(path: Path) -> np.ndarray:\n",
    "    if path.suffix.lower() in {'.tif', '.tiff'}:\n",
    "        arr = tifffile.imread(path)\n",
    "    else:\n",
    "        arr = cv2.imread(str(path), cv2.IMREAD_UNCHANGED)\n",
    "    if arr is None: raise FileNotFoundError(f\"Missing image: {path}\")\n",
    "    if arr.ndim == 3: arr = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY)\n",
    "    return arr\n",
    "\n",
    "def _load_label_mask(path: Path) -> np.ndarray:\n",
    "    mask = tifffile.imread(path)\n",
    "    if mask.ndim == 3: mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
    "    return mask.astype(np.int32)\n",
    "\n",
    "class StarDistDataset(Dataset):\n",
    "    def __init__(self, pairs, n_rays=32):\n",
    "        self.pairs = pairs\n",
    "        self.n_rays = n_rays\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, mask_path = self.pairs[idx]\n",
    "        img = _load_gray(img_path)\n",
    "        mask = _load_label_mask(mask_path)\n",
    "        \n",
    "        # Normalize Image (1-99.8 percentile)\n",
    "        p1, p99 = np.percentile(img, (1, 99.8))\n",
    "        img = np.clip(img, p1, p99)\n",
    "        img = (img - p1) / (p99 - p1 + 1e-8)\n",
    "        img = img.astype(np.float32)\n",
    "        \n",
    "        # Generate Targets\n",
    "        # gen_stardist_maps returns (n_rays, H, W)\n",
    "        dist_map = gen_stardist_maps(mask, n_rays=self.n_rays)\n",
    "        \n",
    "        # Binary map (Prob) - Shape (1, H, W)\n",
    "        binary_map = (mask > 0).astype(np.float32)\n",
    "        binary_map = binary_map[np.newaxis, ...]\n",
    "        \n",
    "        # Image tensor (1, H, W)\n",
    "        img_tensor = torch.from_numpy(img[np.newaxis, ...])\n",
    "        dist_tensor = torch.from_numpy(dist_map)\n",
    "        binary_tensor = torch.from_numpy(binary_map)\n",
    "        \n",
    "        return {\n",
    "            \"image\": img_tensor,\n",
    "            \"stardist_map\": dist_tensor, \n",
    "            \"binary_map\": binary_tensor,\n",
    "            \"id\": str(img_path.name)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5415b3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarDistLightning(pl.LightningModule):\n",
    "    def __init__(self, n_rays=32):\n",
    "        super().__init__()\n",
    "        # Initialize StarDist model from cellseg_models_pytorch\n",
    "        # We use a ResNet18 encoder, 1 input channel (gray), 1 output class (foreground)\n",
    "        wrapper = StarDist(\n",
    "            n_nuc_classes=1, \n",
    "            n_rays=n_rays,\n",
    "            enc_name=\"resnet18\",\n",
    "            model_kwargs={\"encoder_kws\": {\"in_chans\": 1}}\n",
    "        )\n",
    "        self.model = wrapper.model\n",
    "        self.lambda_dist = 1.0 # Weight for distance loss\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images = batch[\"image\"]\n",
    "        gt_dist = batch[\"stardist_map\"] # (B, n_rays, H, W)\n",
    "        gt_bin = batch[\"binary_map\"]    # (B, 1, H, W)\n",
    "        \n",
    "        out = self(images) # Returns dict keys: nuc, etc.\n",
    "        nuc_out = out[\"nuc\"]\n",
    "        \n",
    "        pred_dist = nuc_out.aux_map   # (B, n_rays, H, W)\n",
    "        pred_bin = nuc_out.binary_map # (B, 1, H, W)\n",
    "        \n",
    "        # Losses\n",
    "        # 1. Binary Loss (BCE)\n",
    "        loss_prob = F.binary_cross_entropy_with_logits(pred_bin, gt_bin)\n",
    "        \n",
    "        # 2. Dist Loss (L1, masked by object presence)\n",
    "        l1 = F.l1_loss(pred_dist, gt_dist, reduction='none')\n",
    "        mask = gt_bin.expand_as(l1)\n",
    "        loss_dist = (l1 * mask).sum() / (mask.sum() + 1e-8)\n",
    "        \n",
    "        total_loss = loss_prob + self.lambda_dist * loss_dist\n",
    "        \n",
    "        self.log(\"train_loss\", total_loss, prog_bar=True)\n",
    "        self.log(\"loss_prob\", loss_prob)\n",
    "        self.log(\"loss_dist\", loss_dist)\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.training_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f35c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _list_image_mask_pairs(root: Path):\n",
    "    images = sorted((Path(root) / \"images\").glob(\"*\"))\n",
    "    mask_lookup = {}\n",
    "    masks_root = Path(root) / \"masks\"\n",
    "    for ext in (\"*.tif\", \"*.tiff\", \"*.png\"):\n",
    "        for p in masks_root.glob(ext):\n",
    "            mask_lookup[p.stem] = p\n",
    "    pairs = []\n",
    "    for img_path in images:\n",
    "        mask_path = mask_lookup.get(img_path.stem)\n",
    "        if mask_path: pairs.append((img_path, mask_path))\n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316fc997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kfold(k_splits=2, epochs=20):\n",
    "    SAVE_DIR = Path(\"stardist_checkpoints\")\n",
    "    SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    video_root = Path(\"experiment_dataset/video\")\n",
    "    bonus_root = Path(\"experiment_dataset/bonus\")\n",
    "    \n",
    "    pairs = _list_image_mask_pairs(video_root)\n",
    "    # Include bonus data?\n",
    "    bonus_pairs = _list_image_mask_pairs(bonus_root)\n",
    "    if bonus_pairs:\n",
    "        print(f\"Adding {len(bonus_pairs)} bonus pairs to training.\")\n",
    "        pairs += bonus_pairs\n",
    "        \n",
    "    kf = KFold(n_splits=k_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    best_models = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(pairs), 1):\n",
    "        print(f\"\\n=== Training Fold {fold}/{k_splits} ===\")\n",
    "        train_pairs = [pairs[i] for i in train_idx]\n",
    "        val_pairs = [pairs[i] for i in val_idx]\n",
    "        \n",
    "        train_ds = StarDistDataset(train_pairs, n_rays=N_RAYS)\n",
    "        val_ds = StarDistDataset(val_pairs, n_rays=N_RAYS)\n",
    "        \n",
    "        train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=2 if os.name != 'nt' else 0)\n",
    "        val_loader = DataLoader(val_ds, batch_size=1, shuffle=False)\n",
    "        \n",
    "        model = StarDistLightning(n_rays=N_RAYS)\n",
    "        \n",
    "        checkpoint_callback = ModelCheckpoint(\n",
    "            dirpath=SAVE_DIR, \n",
    "            filename=f\"stardist_fold_{fold}\",\n",
    "            monitor=\"val_loss\",\n",
    "            mode=\"min\",\n",
    "            save_top_k=1\n",
    "        )\n",
    "        \n",
    "        trainer = pl.Trainer(\n",
    "            max_epochs=epochs,\n",
    "            accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "            devices=1,\n",
    "            default_root_dir=SAVE_DIR,\n",
    "            callbacks=[checkpoint_callback],\n",
    "            log_every_n_steps=5\n",
    "        )\n",
    "        \n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        \n",
    "        print(f\"Fold {fold} Best Model: {checkpoint_callback.best_model_path}\")\n",
    "        best_models.append(checkpoint_callback.best_model_path)\n",
    "        \n",
    "    return best_models\n",
    "\n",
    "# Run Training\n",
    "best_model_paths = train_kfold(k_splits=2, epochs=EPOCHS)\n",
    "print(\"Best Models:\", best_model_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49926c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_detections(model_path, out_dir=\"predictions\"):\n",
    "    print(f\"Generating detections using {model_path}...\")\n",
    "    model = StarDistLightning.load_from_checkpoint(model_path)\n",
    "    model.eval()\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    \n",
    "    # Predict on Video frames\n",
    "    video_root = Path(\"experiment_dataset/video\")\n",
    "    img_paths = sorted((video_root / \"images\").glob(\"*\"))\n",
    "    video_map_path = Path(\"experiment_dataset/video_map.csv\")\n",
    "    if not video_map_path.exists():\n",
    "        print(\"Video map not found, cannot map to frames.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    frame_lookup = pd.read_csv(video_map_path).set_index(\"filename\")[\"real_frame_idx\"].to_dict()\n",
    "    \n",
    "    all_detections = []\n",
    "    \n",
    "    for img_path in img_paths:\n",
    "        img = _load_gray(img_path)\n",
    "        # Normalize\n",
    "        p1, p99 = np.percentile(img, (1, 99.8))\n",
    "        img_n = np.clip(img, p1, p99)\n",
    "        img_n = (img_n - p1) / (p99 - p1 + 1e-8)\n",
    "        img_n = img_n.astype(np.float32)\n",
    "        \n",
    "        inp = torch.from_numpy(img_n[np.newaxis, np.newaxis, ...])\n",
    "        if torch.cuda.is_available():\n",
    "            inp = inp.cuda()\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            out = model(inp)\n",
    "            # Binary prob: (1, 1, H, W)\n",
    "            prob_map = torch.sigmoid(out[\"nuc\"].binary_map).cpu().numpy().squeeze() \n",
    "            # Dist map: (1, 32, H, W)\n",
    "            dist_map = out[\"nuc\"].aux_map.cpu().numpy().squeeze()\n",
    "            \n",
    "        # If batch dim was squeezed out differently, ensure shapes:\n",
    "        if prob_map.ndim == 3: prob_map = prob_map[0] # Handle case just in case\n",
    "        \n",
    "        # StarDist Post-processing\n",
    "        # prob_map: (H, W), dist_map: (n_rays, H, W)\n",
    "        # post_proc_stardist expects (prob, dist)\n",
    "        \n",
    "        labels = post_proc_stardist(\n",
    "            dist_map=prob_map,\n",
    "            stardist_map=dist_map,\n",
    "            score_thresh=0.5,\n",
    "            iou_thresh=0.3, # NMS IoU threshold\n",
    "        )\n",
    "        \n",
    "        # Extract centroids\n",
    "        props = regionprops(labels)\n",
    "        frame_idx = frame_lookup.get(img_path.name, 0)\n",
    "        \n",
    "        for p in props:\n",
    "            # Centroid is (y, x)\n",
    "            y, x = p.centroid\n",
    "            all_detections.append({\n",
    "                \"frame\": frame_idx, \n",
    "                \"x\": x, \n",
    "                \"y\": y\n",
    "            })\n",
    "            \n",
    "    df = pd.DataFrame(all_detections)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    csv_path = Path(out_dir) / \"stardist_detections.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Saved {len(df)} detections to {csv_path}\")\n",
    "    return df\n",
    "\n",
    "# Run on the last best model\n",
    "if best_model_paths:\n",
    "    detections_df = generate_detections(best_model_paths[-1])\n",
    "else:\n",
    "    print(\"No models trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae2bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_btrack_tracking(detections_df, config_file=\"btrack_config.json\"):\n",
    "    if detections_df is None or detections_df.empty:\n",
    "        print(\"No detections to track.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if btrack is None:\n",
    "        print(\"Btrack library not available.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Running btrack...\")\n",
    "    # Convert to btrack objects\n",
    "    # btrack expects a list of objects usually, or a dataframe\n",
    "    # We can use create_objects_from_array\n",
    "    \n",
    "    data = detections_df[['x', 'y', 'frame']].copy()\n",
    "    \n",
    "    objects = btrack.create_objects_from_array(\n",
    "        data.to_dict(orient=\"records\"), \n",
    "        properties=['x', 'y']\n",
    "    )\n",
    "    \n",
    "    # Config\n",
    "    if not os.path.exists(config_file):\n",
    "        print(\"Creating default btrack config...\")\n",
    "        cfg = {\n",
    "             \"MotionModel\": {\n",
    "                \"name\": \"cell_motion\",\n",
    "                \"dt\": 1.0,\n",
    "                \"measurements\": 3,\n",
    "                \"states\": 6,\n",
    "                \"accuracy\": 7.5,\n",
    "                \"prob_not_assign\": 0.1,\n",
    "                \"max_lost\": 5,\n",
    "                \"enable_optimization\": True\n",
    "            },\n",
    "            \"HypothesisModel\": {\n",
    "                \"name\": \"cell_hypothesis\",\n",
    "                \"hypotheses\": [\"P_FP\", \"P_init\", \"P_term\", \"P_link\", \"P_branch\", \"P_dead\"],\n",
    "                \"lambda_time\": 5.0,\n",
    "                \"lambda_dist\": 3.0,\n",
    "                \"lambda_link\": 10.0,\n",
    "                \"lambda_branch\": 50.0,\n",
    "                \"eta\": 1e-10,\n",
    "                \"theta_dist\": 20.0,\n",
    "                \"theta_time\": 5.0,\n",
    "                \"dist_thresh\": 40.0,\n",
    "                \"time_thresh\": 2.0,\n",
    "                \"apop_thresh\": 5,\n",
    "                \"segmentation_miss_rate\": 0.1,\n",
    "                \"apoptosis_rate\": 0.001,\n",
    "                \"relax\": True\n",
    "            }\n",
    "         }\n",
    "        with open(config_file, \"w\") as f:\n",
    "            json.dump(cfg, f, indent=2)\n",
    "\n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        tracker.configure(config_file)\n",
    "        tracker.append(objects)\n",
    "        tracker.max_search_radius = 50.0 \n",
    "        tracker.volume = ((0, 1024), (0, 1024), (-1e5, 1e5))\n",
    "        tracker.track_interactive(step_size=100) # or tracker.track()\n",
    "        tracker.optimize()\n",
    "        \n",
    "        tracks = tracker.to_pandas()\n",
    "        \n",
    "    print(f\"BTrack finished. Found {len(tracks['track_id'].unique())} tracks.\")\n",
    "    return tracks\n",
    "\n",
    "# Run BTrack\n",
    "btrack_tracks = run_btrack_tracking(detections_df)\n",
    "if not btrack_tracks.empty:\n",
    "    btrack_tracks.to_csv(\"btrack_results.csv\", index=False)\n",
    "    print(\"Saved btrack_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3527fca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_laptrack_tracking(detections_df):\n",
    "    if detections_df is None or detections_df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    if laptrack is None:\n",
    "        print(\"LapTrack not available.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(\"Running LapTrack...\")\n",
    "    lt = LapTrack(\n",
    "        track_dist_metric=\"sqeuclidean\",\n",
    "        track_cost_cutoff=30.0**2,\n",
    "        gap_closing_max_frame_count=2,\n",
    "        splitting_cost_cutoff=False, # Disable splitting for now\n",
    "        merging_cost_cutoff=False\n",
    "    )\n",
    "    \n",
    "    # Laptrack expects columns: [frame, x, y] (in that order if just array)\n",
    "    # Or specific input format.\n",
    "    # The 'predict_dataframe' method is convenient.\n",
    "    # It expects: frame, x, y columns.\n",
    "    \n",
    "    try:\n",
    "        track_df, split_df, merge_df = lt.predict_dataframe(\n",
    "            detections_df,\n",
    "            coordinate_cols=[\"x\", \"y\"],\n",
    "            frame_col=\"frame\",\n",
    "            only_coordinate_cols=False,\n",
    "            validate_frame_col=False\n",
    "        )\n",
    "        print(f\"LapTrack finished. Found {len(track_df['track_id'].unique())} tracks.\")\n",
    "        return track_df\n",
    "    except Exception as e:\n",
    "        print(f\"LapTrack error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Run LapTrack\n",
    "lap_tracks = run_laptrack_tracking(detections_df)\n",
    "if not lap_tracks.empty:\n",
    "    lap_tracks.to_csv(\"laptrack_results.csv\", index=False)\n",
    "    print(\"Saved laptrack_results.csv\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
