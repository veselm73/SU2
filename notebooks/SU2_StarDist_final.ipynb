{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/veselm73/SU2/blob/main/notebooks/SU2_StarDist_final.ipynb)\n\n# StarDist Cell Detection Training Pipeline\n\nThis notebook trains a StarDist model for cell detection using K-Fold cross-validation.\n\n**Key Features:**\n- StarDist architecture with configurable backbone (ResNet18/34/50, EfficientNet)\n- Combined loss function (Focal + Dice + Smooth L1)\n- Data augmentation with albumentations\n- Regularization: Weight decay + LR scheduling + Early stopping\n- Post-training threshold sweep for optimal prob_thresh/nms_thresh\n- Tracking evaluation with HOTA metric and LapTrack parameter sweep\n\n**Data Sources:**\n- Validation video: Downloaded from UTIA server\n- Bonus training data: Fetched from GitHub repository (annotated frames)\n\n**Outputs:**\n- Trained StarDist model (best fold)\n- Detection predictions CSV\n- Training curves and metrics\n- Tracking visualization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# REPOSITORY CONFIGURATION\n",
    "# ============================================================\n",
    "# Set these if running from Colab or a different location\n",
    "\n",
    "REPO_URL = \"https://github.com/veselm73/SU2\"\n",
    "REPO_BRANCH = \"main\"\n",
    "\n",
    "# Path to bonus training data within the repo\n",
    "BONUS_DATA_SUBPATH = \"annotation/sam_data/unet_train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies using uv (much faster than pip)\n",
    "!pip install uv -q\n",
    "\n",
    "# Uninstall conflicting packages  \n",
    "!uv pip uninstall torch torchvision torchaudio tensorflow tensorflow-metal --system -q 2>/dev/null || true\n",
    "\n",
    "# Install PyTorch with CUDA 12.1\n",
    "!uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 --system -q\n",
    "\n",
    "# Install other dependencies (numpy<2 for compatibility)\n",
    "!uv pip install \"numpy<2\" cellseg-models-pytorch pytorch-lightning laptrack btrack \"albumentations>=1.3.1\" tifffile opencv-python-headless --system -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Check if running in Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Clone repo if not already present, otherwise pull latest\n",
    "    if not Path('/content/SU2').exists():\n",
    "        !git clone https://github.com/veselm73/SU2.git /content/SU2\n",
    "    else:\n",
    "        !cd /content/SU2 && git pull\n",
    "    os.chdir('/content/SU2')\n",
    "    repo_root = Path('/content/SU2')\n",
    "else:\n",
    "    # Local setup - find repo root\n",
    "    notebook_dir = Path(os.getcwd())\n",
    "    if notebook_dir.name == 'notebooks':\n",
    "        repo_root = notebook_dir.parent\n",
    "    else:\n",
    "        repo_root = notebook_dir\n",
    "\n",
    "if str(repo_root) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_root))\n",
    "\n",
    "print(f\"Repository root: {repo_root}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Import helper functions\nfrom modules.stardist_helpers import (\n    # Data fetching\n    download_validation_data,\n    fetch_training_data_from_github,\n    prepare_grand_dataset,\n    create_stardist_label_mask,\n    # Training\n    train_stardist_kfold,\n    infer_stardist_full_video,\n    sweep_stardist_thresholds,\n    # Metrics\n    calculate_deta_robust,\n    hota,\n    # Tracking\n    run_laptrack,\n    # Visualization\n    plot_training_history,\n    show_detection_overlay,\n    show_tracking_animation,\n    print_results_summary,\n    # Utilities\n    set_seed,\n    get_device,\n    ROI_X_MIN, ROI_X_MAX, ROI_Y_MIN, ROI_Y_MAX\n)\n\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nset_seed(42)\ndevice = get_device()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation\n",
    "\n",
    "This section downloads/fetches the required data:\n",
    "1. **Validation video**: From UTIA server (val.tif + val.csv)\n",
    "2. **Bonus training data**: From GitHub repository (annotated frames with masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "VAL_DIR = repo_root / \"data\" / \"val\"\n",
    "VAL_TIF = VAL_DIR / \"val.tif\"\n",
    "VAL_CSV = VAL_DIR / \"val.csv\"\n",
    "BONUS_DATA_DIR = repo_root / \"bonus_training_data\"\n",
    "\n",
    "print(\"Data paths:\")\n",
    "print(f\"  Validation: {VAL_DIR}\")\n",
    "print(f\"  Bonus data: {BONUS_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download validation data from UTIA server\n",
    "if not VAL_TIF.exists():\n",
    "    print(\"Downloading validation data from UTIA server...\")\n",
    "    download_validation_data(target_dir=str(VAL_DIR))\n",
    "else:\n",
    "    print(f\"Validation data exists: {VAL_TIF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch bonus training data from GitHub\n",
    "# This will:\n",
    "# 1. Check if data exists locally (in cloned repo)\n",
    "# 2. If not, download from GitHub API\n",
    "\n",
    "bonus_path = fetch_training_data_from_github(\n",
    "    repo_url=REPO_URL,\n",
    "    branch=REPO_BRANCH,\n",
    "    data_subpath=BONUS_DATA_SUBPATH,\n",
    "    target_dir=str(BONUS_DATA_DIR),\n",
    "    use_local_if_available=True\n",
    ")\n",
    "\n",
    "if bonus_path:\n",
    "    print(f\"\\nBonus data ready at: {bonus_path}\")\n",
    "else:\n",
    "    print(\"\\nWarning: Could not fetch bonus data. Training will use only video frames.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset structure (creates experiment_dataset/)\n",
    "# This combines:\n",
    "# - Video frames cropped to ROI with generated disk masks\n",
    "# - Bonus annotated frames with instance masks\n",
    "\n",
    "DATASET_DIR = repo_root / \"experiment_dataset\"\n",
    "DISK_RADIUS = 3  # Radius for disk masks (3px for precise localization)\n",
    "\n",
    "print(\"Preparing combined dataset...\")\n",
    "prepare_grand_dataset(\n",
    "    bonus_data_dir=str(BONUS_DATA_DIR) if bonus_path else None,\n",
    "    val_tif_path=str(VAL_TIF),\n",
    "    val_csv_path=str(VAL_CSV),\n",
    "    out_dir=str(DATASET_DIR),\n",
    "    disk_radius=DISK_RADIUS\n",
    ")\n",
    "\n",
    "VIDEO_MAP_PATH = DATASET_DIR / \"video_map.csv\"\n",
    "print(f\"\\nDataset ready at: {DATASET_DIR}\")\n",
    "print(f\"Video frame map: {VIDEO_MAP_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Configuration\n",
    "\n",
    "Configure the training parameters below.\n",
    "\n",
    "**Mode selection:**\n",
    "- **Baseline mode**: Set `USE_AUGMENTATION = False`, `WEIGHT_DECAY = 0`\n",
    "- **Improved mode**: Use defaults (all regularization features enabled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# TRAINING CONFIGURATION - FINAL RUN FOR BEST DetA\n# ============================================================\n\n# Basic training parameters - EXTENDED FOR FINAL RUN\nK_SPLITS = 5          # Number of cross-validation folds\nEPOCHS = 100          # Extended epochs for thorough training\nBATCH_SIZE = 4        # Batch size (reduce if OOM)\nLR = 1e-4             # Initial learning rate\n\n# StarDist model parameters\nN_RAYS = 32           # Number of radial directions (32, 64, or 96)\nENCODER_NAME = \"resnet18\"  # Backbone: resnet18, resnet34, resnet50, efficientnet-b0\n\n# Detection thresholds - FIXED during training (ensemble sweep later)\nPROB_THRESH = 0.3     # Fixed threshold for training\nNMS_THRESH = 0.3      # Fixed NMS threshold\nMATCH_THRESH = 5.0    # Distance threshold for DetA calculation (pixels)\n\n# Data options\nUSE_BONUS = True      # Include bonus training data from GitHub\n\n# Output directory\nSAVE_DIR = repo_root / \"results\" / \"stardist\"\n\n# ============================================================\n# FINAL RUN CONFIGURATION - OPTIMIZED FOR BEST DetA\n# ============================================================\n# Based on experiments:\n# - BASELINE loss (BCE + L1) performs best on this dataset\n# - Light augmentation helps generalization\n# - Moderate dropout (0.1) prevents overfitting\n# - NO per-fold threshold sweep (ensemble sweep at the end)\n\nTRAINING_MODE = \"FINAL\"  # Custom mode for final run\n\n# Loss settings (BASELINE performs best)\nUSE_SIMPLE_BCE = True   # Simple BCE outperforms Focal on this dataset\nUSE_SIMPLE_L1 = True    # Simple L1 outperforms Smooth L1\nFOCAL_WEIGHT = 1.0\nDICE_WEIGHT = 0.0       # Disabled - not helpful for this task\nDIST_WEIGHT = 1.0\n\n# Regularization\nDROPOUT = 0.1           # Light dropout\nWEIGHT_DECAY = 0.0      # No weight decay (BASELINE)\n\n# Light augmentation (helps generalization without distorting cells)\nUSE_AUGMENTATION = True\nAUG_PARAMS = {\n    'rotate_p': 0.3,      # Light rotation\n    'flip_p': 0.5,        # Flips are safe for cells\n    'brightness_p': 0.2,  # Light brightness variation\n    'noise_p': 0.1,       # Very light noise\n    'blur_p': 0.0,        # No blur\n    'elastic_p': 0.0      # No elastic (distorts cells)\n}\n\n# Training schedule - patient for best convergence\nEARLY_STOPPING_PATIENCE = 30  # Very patient - let it converge\nSCHEDULER_PATIENCE = 10       # Reduce LR after 10 epochs plateau\nSCHEDULER_FACTOR = 0.5        # Halve LR on plateau\n\n# ============================================================\n# THRESHOLD SWEEP STRATEGY\n# ============================================================\n# NO per-fold sweep during training (saves time, avoids overfitting)\n# Ensemble threshold sweep will be done AFTER training on OOF predictions\nRUN_THRESHOLD_SWEEP = False  # Disabled - will do ensemble sweep later\n\n# These will be used for ensemble sweep after training\nENSEMBLE_PROB_THRESHOLDS = [0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5]\nENSEMBLE_NMS_THRESHOLDS = [0.1, 0.2, 0.3, 0.4, 0.5]\n\n# Print configuration\nprint(\"=\" * 60)\nprint(\"FINAL RUN CONFIGURATION - OPTIMIZED FOR BEST DetA\")\nprint(\"=\" * 60)\nprint(f\"\\nModel:\")\nprint(f\"  Encoder: {ENCODER_NAME}, N_Rays: {N_RAYS}\")\nprint(f\"  Dropout: {DROPOUT}\")\nprint(f\"\\nTraining:\")\nprint(f\"  Epochs: {EPOCHS} (extended)\")\nprint(f\"  Batch Size: {BATCH_SIZE}, LR: {LR}\")\nprint(f\"  Early Stopping: patience={EARLY_STOPPING_PATIENCE}\")\nprint(f\"  LR Scheduler: patience={SCHEDULER_PATIENCE}, factor={SCHEDULER_FACTOR}\")\nprint(f\"\\nLoss: BCE + L1 (BASELINE - best for this dataset)\")\nprint(f\"\\nAugmentation: {USE_AUGMENTATION}\")\nif USE_AUGMENTATION:\n    print(f\"  rotate_p={AUG_PARAMS['rotate_p']}, flip_p={AUG_PARAMS['flip_p']}\")\n    print(f\"  brightness_p={AUG_PARAMS['brightness_p']}, noise_p={AUG_PARAMS['noise_p']}\")\nprint(f\"\\nThreshold Strategy:\")\nprint(f\"  Per-fold sweep: DISABLED (faster training)\")\nprint(f\"  Fixed threshold during training: prob={PROB_THRESH}, nms={NMS_THRESH}\")\nprint(f\"  Ensemble sweep after training: {len(ENSEMBLE_PROB_THRESHOLDS)}x{len(ENSEMBLE_NMS_THRESHOLDS)} combinations\")\nprint(f\"\\nSave directory: {SAVE_DIR}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training\n",
    "\n",
    "Run K-Fold cross-validation training. Each fold:\n",
    "1. Trains with combined loss (Focal + Dice + Smooth L1)\n",
    "2. Uses LR scheduling and early stopping\n",
    "3. Runs threshold sweep to find optimal prob/nms thresholds\n",
    "4. Evaluates DetA metric on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run training (NO per-fold threshold sweep - will do ensemble sweep later)\nfold_results, best_fold, all_preds_df = train_stardist_kfold(\n    dataset_root=DATASET_DIR,\n    video_map_path=VIDEO_MAP_PATH,\n    val_csv_path=str(VAL_CSV),\n    k_splits=K_SPLITS,\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    lr=LR,\n    n_rays=N_RAYS,\n    prob_thresh=PROB_THRESH,\n    nms_thresh=NMS_THRESH,\n    use_bonus=USE_BONUS,\n    save_dir=SAVE_DIR,\n    match_thresh=MATCH_THRESH,\n    device=device,\n    # Improvement parameters\n    use_augmentation=USE_AUGMENTATION,\n    aug_params=AUG_PARAMS if USE_AUGMENTATION else None,\n    weight_decay=WEIGHT_DECAY,\n    focal_weight=FOCAL_WEIGHT,\n    dice_weight=DICE_WEIGHT,\n    dist_weight=DIST_WEIGHT,\n    scheduler_patience=SCHEDULER_PATIENCE,\n    scheduler_factor=SCHEDULER_FACTOR,\n    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n    encoder_name=ENCODER_NAME,\n    # NO per-fold threshold sweep (ensemble sweep after training)\n    run_threshold_sweep=False,\n    # Baseline mode: use simple BCE + L1\n    use_simple_bce=USE_SIMPLE_BCE,\n    use_simple_l1=USE_SIMPLE_L1,\n    # Dropout for regularization\n    dropout=DROPOUT\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Display fold results summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"K-FOLD TRAINING RESULTS\")\nprint(\"=\"*60)\n\nfor result in fold_results:\n    print(f\"\\nFold {result['fold']}:\")\n    print(f\"  DetA = {result['deta']:.4f} (with fixed thresh: prob={PROB_THRESH}, nms={NMS_THRESH})\")\n    print(f\"  Stopped at epoch: {result['stopped_epoch']}\")\n\ndeta_values = [r['deta'] for r in fold_results]\nprint(f\"\\n\" + \"-\"*40)\nprint(f\"Mean DetA: {np.mean(deta_values):.4f} +/- {np.std(deta_values):.4f}\")\nprint(f\"Best Fold: {best_fold['fold']} (DetA = {best_fold['deta']:.4f})\")\nprint(f\"\\nNote: These DetA values use fixed threshold {PROB_THRESH}\")\nprint(f\"Ensemble threshold sweep will optimize this next.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training curves for best fold\n",
    "history = best_fold['history']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history['train_loss'], label='Train Loss', color='blue', linewidth=2)\n",
    "ax1.plot(history['val_loss'], label='Val Loss', color='orange', linewidth=2)\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title(f'Training Curves - Best Fold {best_fold[\"fold\"]}')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "ax2 = axes[1]\n",
    "if 'lr' in history and history['lr']:\n",
    "    ax2.plot(history['lr'], color='green', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Learning Rate')\n",
    "    ax2.set_title('Learning Rate Schedule')\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'LR history not available', ha='center', va='center', transform=ax2.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(SAVE_DIR / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## 6. Ensemble Threshold Sweep\n\nNow we find the **optimal threshold for ensemble inference** by sweeping on OOF predictions.\n\nThis is NOT data leakage because:\n- Each frame's prediction comes from a model that didn't see it during training\n- We're finding one global threshold for the entire ensemble",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Ensemble threshold sweep on OOF predictions\n# This finds the optimal threshold for all models combined\n\nfrom tqdm.auto import tqdm\nimport tifffile\n\nprint(\"=\" * 60)\nprint(\"ENSEMBLE THRESHOLD SWEEP\")\nprint(\"=\" * 60)\nprint(f\"\\nSweeping {len(ENSEMBLE_PROB_THRESHOLDS)} x {len(ENSEMBLE_NMS_THRESHOLDS)} = {len(ENSEMBLE_PROB_THRESHOLDS) * len(ENSEMBLE_NMS_THRESHOLDS)} combinations\")\n\n# Load ground truth\ngt_df = pd.read_csv(VAL_CSV)\ngt_roi = gt_df[\n    (gt_df.x >= ROI_X_MIN) & (gt_df.x < ROI_X_MAX) &\n    (gt_df.y >= ROI_Y_MIN) & (gt_df.y < ROI_Y_MAX)\n].copy()\n\n# Load video for re-inference with different thresholds\nvideo = tifffile.imread(VAL_TIF)\nvideo_roi = video[:, ROI_Y_MIN:ROI_Y_MAX, ROI_X_MIN:ROI_X_MAX]\n\n# Get video frame indices from the dataset\nvideo_map = pd.read_csv(VIDEO_MAP_PATH)\nvideo_frames = video_map[video_map['source'] == 'video']['frame'].tolist()\n\n# We need to re-run inference with different thresholds\n# Use all fold models and average their probability outputs\nfrom cellseg_models_pytorch.postproc.functional.stardist.stardist import post_proc_stardist\nfrom skimage.measure import regionprops\n\nbest_deta = 0\nbest_prob_thresh = PROB_THRESH\nbest_nms_thresh = NMS_THRESH\nsweep_results = []\n\n# Move all models to device\nfor result in fold_results:\n    result['model'].to(device)\n    result['model'].eval()\n\nfor prob_t in tqdm(ENSEMBLE_PROB_THRESHOLDS, desc=\"prob_thresh\"):\n    for nms_t in ENSEMBLE_NMS_THRESHOLDS:\n        # Run ensemble inference on all video frames\n        all_preds = []\n        \n        for frame_idx in video_frames:\n            frame = video_roi[frame_idx].astype(np.float32)\n            frame_norm = (frame - frame.mean()) / (frame.std() + 1e-8)\n            x = torch.from_numpy(frame_norm).float().unsqueeze(0).unsqueeze(0).to(device)\n            \n            # Collect predictions from all folds and average\n            all_dist = []\n            all_bin = []\n            \n            with torch.no_grad():\n                for result in fold_results:\n                    model = result['model']\n                    pred_dist, pred_bin = model.model(x)\n                    all_dist.append(pred_dist.cpu().numpy()[0])\n                    all_bin.append(torch.sigmoid(pred_bin).cpu().numpy()[0, 0])\n            \n            # Average across folds\n            avg_dist = np.mean(all_dist, axis=0)\n            avg_bin = np.mean(all_bin, axis=0)\n            \n            # Post-process with current thresholds\n            try:\n                labels = post_proc_stardist(avg_dist, avg_bin, prob_thresh=prob_t, nms_thresh=nms_t)\n                for prop in regionprops(labels):\n                    y, cx = prop.centroid\n                    all_preds.append({\n                        'frame': frame_idx,\n                        'x': cx + ROI_X_MIN,\n                        'y': y + ROI_Y_MIN\n                    })\n            except:\n                pass\n        \n        # Calculate DetA\n        if all_preds:\n            preds_df = pd.DataFrame(all_preds)\n            common_frames = set(gt_roi.frame.unique()) & set(preds_df.frame.unique())\n            gt_filtered = gt_roi[gt_roi.frame.isin(common_frames)]\n            pred_filtered = preds_df[preds_df.frame.isin(common_frames)]\n            deta = calculate_deta_robust(gt_filtered, pred_filtered, match_thresh=MATCH_THRESH)\n        else:\n            deta = 0.0\n        \n        sweep_results.append({\n            'prob_thresh': prob_t,\n            'nms_thresh': nms_t,\n            'deta': deta,\n            'n_detections': len(all_preds)\n        })\n        \n        if deta > best_deta:\n            best_deta = deta\n            best_prob_thresh = prob_t\n            best_nms_thresh = nms_t\n            print(f\"  New best: prob={prob_t:.2f}, nms={nms_t:.2f} -> DetA={deta:.4f}\")\n\n# Store results\nsweep_df = pd.DataFrame(sweep_results)\nprint(f\"\\n\" + \"=\" * 60)\nprint(\"ENSEMBLE THRESHOLD SWEEP RESULTS\")\nprint(\"=\" * 60)\nprint(f\"\\nBest ensemble thresholds:\")\nprint(f\"  prob_thresh: {best_prob_thresh}\")\nprint(f\"  nms_thresh: {best_nms_thresh}\")\nprint(f\"  DetA: {best_deta:.4f}\")\n\n# Update best values for downstream use\nbest_prob = best_prob_thresh\nbest_nms = best_nms_thresh",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Final Ensemble Predictions\n\nGenerate final predictions using the **best ensemble thresholds** found in the sweep."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate final ensemble predictions with best thresholds\nprint(f\"Generating final ensemble predictions...\")\nprint(f\"  Using: prob_thresh={best_prob}, nms_thresh={best_nms}\")\n\nfinal_preds = []\n\nfor frame_idx in tqdm(video_frames, desc=\"Ensemble inference\"):\n    frame = video_roi[frame_idx].astype(np.float32)\n    frame_norm = (frame - frame.mean()) / (frame.std() + 1e-8)\n    x = torch.from_numpy(frame_norm).float().unsqueeze(0).unsqueeze(0).to(device)\n    \n    # Average predictions from all folds\n    all_dist = []\n    all_bin = []\n    \n    with torch.no_grad():\n        for result in fold_results:\n            model = result['model']\n            pred_dist, pred_bin = model.model(x)\n            all_dist.append(pred_dist.cpu().numpy()[0])\n            all_bin.append(torch.sigmoid(pred_bin).cpu().numpy()[0, 0])\n    \n    avg_dist = np.mean(all_dist, axis=0)\n    avg_bin = np.mean(all_bin, axis=0)\n    \n    # Post-process with best thresholds\n    try:\n        labels = post_proc_stardist(avg_dist, avg_bin, prob_thresh=best_prob, nms_thresh=best_nms)\n        for prop in regionprops(labels):\n            y, cx = prop.centroid\n            final_preds.append({\n                'frame': frame_idx,\n                'x': cx + ROI_X_MIN,\n                'y': y + ROI_Y_MIN\n            })\n    except:\n        pass\n\nfull_preds_df = pd.DataFrame(final_preds)\n\n# Calculate final DetA\ncommon_frames = set(gt_roi.frame.unique()) & set(full_preds_df.frame.unique())\ngt_filtered = gt_roi[gt_roi.frame.isin(common_frames)]\npred_filtered = full_preds_df[full_preds_df.frame.isin(common_frames)]\n\nfinal_deta = calculate_deta_robust(gt_filtered, pred_filtered, match_thresh=MATCH_THRESH)\n\nprint(f\"\\n\" + \"=\" * 60)\nprint(\"FINAL ENSEMBLE RESULTS\")\nprint(\"=\" * 60)\nprint(f\"Total detections: {len(full_preds_df)}\")\nprint(f\"Frames covered: {full_preds_df['frame'].nunique()}\")\nprint(f\"Final DetA: {final_deta:.4f}\")\nprint(f\"Thresholds: prob={best_prob}, nms={best_nms}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. Tracking\n\n**Note on Parameter Selection:** We use fixed tracking parameters (not tuned on GT) to avoid data leakage. These defaults are based on typical cell movement characteristics:\n- `track_cost_cutoff=25` (5px): Maximum squared distance for frame-to-frame linking\n- `gap_closing_cost_cutoff=25`: Distance for gap closing\n- `gap_closing_max_frame_count=1`: Maximum frames to skip for gap closing\n\nThis ensures HOTA scores reflect what you'll achieve on unknown test data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Run LapTrack with FIXED parameters (no data leakage)\n# Parameters chosen based on typical cell movement (~5 pixels per frame)\n\n# Fixed tracking parameters (not tuned on GT!)\nTRACK_COST_CUTOFF = 25          # 5 pixels squared distance\nGAP_CLOSING_COST_CUTOFF = 25    # 5 pixels for gap closing\nGAP_CLOSING_MAX_FRAMES = 1      # Only close 1-frame gaps\n\n# Run tracking with fixed parameters\ntracked_df = run_laptrack(\n    detections_df=full_preds_df,\n    track_cost_cutoff=TRACK_COST_CUTOFF,\n    gap_closing_cost_cutoff=GAP_CLOSING_COST_CUTOFF,\n    gap_closing_max_frame_count=GAP_CLOSING_MAX_FRAMES\n)\n\nprint(f\"Tracking complete with fixed parameters (no data leakage)!\")\nprint(f\"  track_cost_cutoff: {TRACK_COST_CUTOFF} (â‰ˆ{int(TRACK_COST_CUTOFF**0.5)}px)\")\nprint(f\"  gap_closing_cost_cutoff: {GAP_CLOSING_COST_CUTOFF}\")\nprint(f\"  gap_closing_max_frame_count: {GAP_CLOSING_MAX_FRAMES}\")\nprint(f\"  Total tracks: {tracked_df['track_id'].nunique()}\")\nprint(f\"  Total detections: {len(tracked_df)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Calculate HOTA metrics with fixed tracking parameters\ngt_for_tracking = gt_roi[['frame', 'x', 'y', 'track_id']].copy()\n\nhota_scores = hota(gt_for_tracking, tracked_df, match_thresh=MATCH_THRESH)\n\nprint(\"HOTA Metrics (with fixed tracking parameters - no data leakage):\")\nprint(f\"  HOTA: {hota_scores['HOTA']:.4f}\")\nprint(f\"  DetA: {hota_scores['DetA']:.4f}\")\nprint(f\"  AssA: {hota_scores['AssA']:.4f}\")\n\n# Store for summary\nhota_score = hota_scores['HOTA']"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize sample frames with detections\nimport tifffile\n\nvideo_frames = tifffile.imread(VAL_TIF)\nroi = video_frames[:, ROI_Y_MIN:ROI_Y_MAX, ROI_X_MIN:ROI_X_MAX]\n\nsample_frames = [0, 30, 60, 90]\nfig, axes = plt.subplots(1, len(sample_frames), figsize=(16, 4))\n\nfor ax, fidx in zip(axes, sample_frames):\n    if fidx >= len(roi):\n        continue\n    \n    ax.imshow(roi[fidx], cmap='gray')\n    \n    # Plot GT (green circles)\n    frame_gt = gt_roi[gt_roi.frame == fidx]\n    ax.scatter(\n        frame_gt.x - ROI_X_MIN,\n        frame_gt.y - ROI_Y_MIN,\n        c='lime', s=30, marker='o', alpha=0.8, label='GT'\n    )\n    \n    # Plot predictions (red crosses)\n    frame_preds = full_preds_df[full_preds_df.frame == fidx]\n    ax.scatter(\n        frame_preds.x - ROI_X_MIN,\n        frame_preds.y - ROI_Y_MIN,\n        c='red', s=20, marker='x', alpha=0.8, label='Predicted'\n    )\n    \n    ax.set_title(f'Frame {fidx}')\n    ax.axis('off')\n\naxes[0].legend(loc='upper left')\nplt.suptitle('StarDist Detection Results', fontsize=14)\nplt.tight_layout()\nplt.savefig(SAVE_DIR / 'detection_samples.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Save predictions and tracking results\nSAVE_DIR.mkdir(parents=True, exist_ok=True)\n\nfull_preds_df.to_csv(SAVE_DIR / 'stardist_predictions.csv', index=False)\ntracked_df.to_csv(SAVE_DIR / 'stardist_tracked.csv', index=False)\n\n# Save summary\nsummary = {\n    'best_fold': best_fold['fold'],\n    'best_deta': best_fold['deta'],\n    'final_deta': final_deta,\n    'hota': hota_score,\n    'deta_from_hota': hota_scores['DetA'],\n    'assa': hota_scores['AssA'],\n    'best_prob_thresh': best_prob,\n    'best_nms_thresh': best_nms,\n    'track_cost_cutoff': TRACK_COST_CUTOFF,\n    'gap_closing_cost_cutoff': GAP_CLOSING_COST_CUTOFF,\n    'gap_closing_max_frame_count': GAP_CLOSING_MAX_FRAMES,\n    'total_detections': len(full_preds_df),\n    'total_tracks': tracked_df['track_id'].nunique(),\n    'use_augmentation': USE_AUGMENTATION,\n    'weight_decay': WEIGHT_DECAY,\n    'encoder': ENCODER_NAME,\n    'n_rays': N_RAYS,\n    'dropout': DROPOUT,\n    'repo_url': REPO_URL\n}\n\npd.DataFrame([summary]).to_csv(SAVE_DIR / 'training_summary.csv', index=False)\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"TRAINING SUMMARY\")\nprint(\"=\"*60)\nprint(\"\\nDetection:\")\nprint(f\"  Best Fold: {summary['best_fold']}\")\nprint(f\"  OOF DetA: {summary['final_deta']:.4f}\")\nprint(f\"  prob_thresh: {summary['best_prob_thresh']:.2f}\")\nprint(f\"  nms_thresh: {summary['best_nms_thresh']:.2f}\")\nprint(\"\\nTracking (HOTA):\")\nprint(f\"  HOTA: {summary['hota']:.4f}\")\nprint(f\"  DetA: {summary['deta_from_hota']:.4f}\")\nprint(f\"  AssA: {summary['assa']:.4f}\")\nprint(f\"\\nResults saved to: {SAVE_DIR}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Export Competition Artifacts\n\nThis section exports all trained models and configurations for competition submission.\n\n**Exported files:**\n- `models/fold_1.pth` ... `fold_5.pth` - All K-fold model weights\n- `model_config.json` - Architecture configuration\n- `inference_config.json` - Optimal thresholds and tracking parameters\n\n**Usage:** Load models and configs to run inference on new test data.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Create competition export directory\nimport json\n\nCOMPETITION_DIR = SAVE_DIR / \"competition\"\nMODELS_DIR = COMPETITION_DIR / \"models\"\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\n\nprint(\"Exporting competition artifacts...\")\nprint(f\"  Export directory: {COMPETITION_DIR}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Export all K-fold models as state_dict (.pth)\nprint(\"\\nExporting fold models...\")\n\nfor result in fold_results:\n    fold_num = result['fold']\n    model = result['model']\n    save_path = MODELS_DIR / f\"fold_{fold_num}.pth\"\n    torch.save(model.state_dict(), save_path)\n    print(f\"  Saved: fold_{fold_num}.pth\")\n\nprint(f\"\\nExported {len(fold_results)} models to {MODELS_DIR}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Export model configuration\nmodel_config = {\n    \"architecture\": \"StarDist\",\n    \"encoder_name\": ENCODER_NAME,\n    \"n_rays\": N_RAYS,\n    \"input_channels\": 1,\n    \"dropout\": DROPOUT\n}\n\nmodel_config_path = COMPETITION_DIR / \"model_config.json\"\nwith open(model_config_path, 'w') as f:\n    json.dump(model_config, f, indent=2)\nprint(f\"\\nSaved: model_config.json\")\n\n# Export inference configuration (optimal thresholds + tracking params)\ninference_config = {\n    \"prob_thresh\": float(best_prob),\n    \"nms_thresh\": float(best_nms),\n    \"track_cost_cutoff\": int(TRACK_COST_CUTOFF),\n    \"gap_closing_cost_cutoff\": int(GAP_CLOSING_COST_CUTOFF),\n    \"gap_closing_max_frame_count\": int(GAP_CLOSING_MAX_FRAMES),\n    \"match_thresh\": float(MATCH_THRESH),\n    \"roi\": {\n        \"x_min\": int(ROI_X_MIN),\n        \"x_max\": int(ROI_X_MAX),\n        \"y_min\": int(ROI_Y_MIN),\n        \"y_max\": int(ROI_Y_MAX)\n    }\n}\n\ninference_config_path = COMPETITION_DIR / \"inference_config.json\"\nwith open(inference_config_path, 'w') as f:\n    json.dump(inference_config, f, indent=2)\nprint(f\"Saved: inference_config.json\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Print export summary\nprint(\"\\n\" + \"=\"*60)\nprint(\"COMPETITION EXPORT COMPLETE\")\nprint(\"=\"*60)\n\nprint(f\"\\nExported to: {COMPETITION_DIR}\")\nprint(\"\\nFiles:\")\nfor item in sorted(COMPETITION_DIR.rglob('*')):\n    if item.is_file():\n        rel_path = item.relative_to(COMPETITION_DIR)\n        size_kb = item.stat().st_size / 1024\n        print(f\"  {rel_path} ({size_kb:.1f} KB)\")\n\nprint(\"\\n\" + \"-\"*60)\nprint(\"USAGE INSTRUCTIONS\")\nprint(\"-\"*60)\nprint(\"\"\"\nTo run inference on new test data:\n\n1. Load model_config.json and inference_config.json\n2. Create StarDistLightning model with config params\n3. Load fold weights (ensemble or single best)\n4. Run inference with prob_thresh/nms_thresh from config\n5. Run LapTrack with tracking params from config\n\nSee SU2_StarDist_export.ipynb for ready-to-use inference API.\n\"\"\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 11. Save Weights to GitHub / Google Drive\n\n**IMPORTANT:** Colab runtime files are deleted when the session ends. Run one of the cells below to persist your trained models.\n\n**Option A (Preferred):** Push to GitHub repository  \n**Option B (Fallback):** Save to Google Drive",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# OPTION A (PREFERRED): Push weights to GitHub\n# ============================================================\n# This saves your trained models directly to the repository\n\nimport subprocess\n\n# Configure git (required for Colab)\n!git config --global user.email \"veselm73@gmail.com\"\n!git config --global user.name \"veselm73\"\n\n# Check current status\nprint(\"Current git status:\")\n!cd {repo_root} && git status --short\n\n# Add competition artifacts to git\n!cd {repo_root} && git add results/stardist/competition/\n\n# Create commit with training results\ncommit_msg = f\"Add trained StarDist models (DetA={final_deta:.4f}, HOTA={hota_score:.4f})\"\n!cd {repo_root} && git commit -m \"{commit_msg}\"\n\n# Push to GitHub (you may need to authenticate)\nprint(\"\\nPushing to GitHub...\")\nprint(\"If prompted, enter your GitHub Personal Access Token as password\")\n!cd {repo_root} && git push\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SUCCESS: Weights pushed to GitHub!\")\nprint(f\"Repository: {REPO_URL}\")\nprint(\"=\"*60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ============================================================\n# OPTION B (FALLBACK): Save to Google Drive\n# ============================================================\n# Use this if GitHub push fails or you prefer Google Drive\n\nfrom google.colab import drive\n\n# Mount Google Drive\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive')\n\n# Create backup directory\nDRIVE_BACKUP_DIR = Path('/content/drive/MyDrive/SU2_competition_backup')\nDRIVE_BACKUP_DIR.mkdir(parents=True, exist_ok=True)\n\n# Copy competition artifacts to Drive\nimport shutil\nshutil.copytree(COMPETITION_DIR, DRIVE_BACKUP_DIR / 'competition', dirs_exist_ok=True)\n\n# Also save training summary and predictions\nshutil.copy(SAVE_DIR / 'training_summary.csv', DRIVE_BACKUP_DIR / 'training_summary.csv')\nshutil.copy(SAVE_DIR / 'stardist_predictions.csv', DRIVE_BACKUP_DIR / 'stardist_predictions.csv')\nshutil.copy(SAVE_DIR / 'stardist_tracked.csv', DRIVE_BACKUP_DIR / 'stardist_tracked.csv')\n\nprint(\"\\n\" + \"=\"*60)\nprint(\"SUCCESS: Weights saved to Google Drive!\")\nprint(f\"Location: {DRIVE_BACKUP_DIR}\")\nprint(\"=\"*60)\n\n# List saved files\nprint(\"\\nSaved files:\")\nfor item in sorted(DRIVE_BACKUP_DIR.rglob('*')):\n    if item.is_file():\n        rel_path = item.relative_to(DRIVE_BACKUP_DIR)\n        size_kb = item.stat().st_size / 1024\n        print(f\"  {rel_path} ({size_kb:.1f} KB)\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}